{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "# data_a = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/preprocessed_data_files/wind_speed_small.csv', delimiter=',')\n",
    "# data_b = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/preprocessed_data_files/energy_generation_solar_small.csv', delimiter=',', skiprows=1)\n",
    "# data_c = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/preprocessed_data_files/heart_rate_small.csv', delimiter=',', skiprows=1)\n",
    "# data_d = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/preprocessed_data_files/temperature_delhi_small.csv', delimiter=',', skiprows=1)\n",
    "# data_e = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/preprocessed_data_files/stock_open_microsoft.csv', delimiter=',', skiprows=1)\n",
    "# data_f = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/preprocessed_data_files/nyctaxitraffic_small.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# Load the datasets\n",
    "#data_a = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv', delimiter=',', skiprows=0)\n",
    "# data_b = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/energy_generation_solar.csv', delimiter=',', skiprows=0)\n",
    "# data_c = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/heart_rate.csv', delimiter=',', skiprows=0)\n",
    "# data_d = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/temperature_delhi.csv', delimiter=',', skiprows=0)\n",
    "# data_e = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/stock_open_microsoft.csv', delimiter=',', skiprows=0)\n",
    "data_f = np.loadtxt('/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/nyctaxitraffic.csv', delimiter=',', skiprows=0)\n",
    "\n",
    "\n",
    "# Define the parameters for testing\n",
    "lags = 2\n",
    "vector = np.array([0.9208, -0.0111, 0.0766])\n",
    "order = 1\n",
    "theta = np.array([0.3, 0.3])\n",
    "\n",
    "# Expected outputs\n",
    "expected_output_ar_a = 8.42711736\n",
    "expected_output_integrated_a = 0.55796623\n",
    "expected_output_ma_a = 8.25047461\n",
    "expected_output_complete_a = 3.059677\n",
    "\n",
    "expected_output_ar_b = 33.09027077\n",
    "expected_output_integrated_b = 1.23456789\n",
    "expected_output_ma_b = 33.56789012\n",
    "expected_output_complete_b = 61.78846\n",
    "\n",
    "expected_output_ar_c = 98.77752695\n",
    "expected_output_integrated_c = 2.34567890\n",
    "expected_output_ma_c = 99.12345678\n",
    "expected_output_complete_c = -6.16423\n",
    "\n",
    "expected_output_complete_d = -1.066503\n",
    "\n",
    "expected_output_complete_e = 6.920413\n",
    "\n",
    "expected_output_complete_f = 1143.753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#####\n",
    "# Autoregressive Component\n",
    "\n",
    "def autoregressive_component_basic(data, lags, vector):\n",
    "    rows = len(data)\n",
    "    lagged_matrix = np.zeros((rows, lags + 1))\n",
    "\n",
    "    for i in range(lags + 1):\n",
    "        for j in range(rows):\n",
    "            if j + i < rows:\n",
    "                lagged_matrix[j, i] = data[j + i]\n",
    "\n",
    "    lagged_matrix = lagged_matrix[:rows - lags]\n",
    "\n",
    "    result = np.zeros(len(lagged_matrix))\n",
    "    for i in range(len(lagged_matrix)):\n",
    "        for j in range(len(vector)):\n",
    "            result[i] += lagged_matrix[i, j] * vector[j]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def autoregressive_component_basic_v2(data, lags, vector):\n",
    "    rows = len(data)\n",
    "    result = np.zeros(rows - lags)\n",
    "\n",
    "    for i in range(rows - lags):\n",
    "        for j in range(lags + 1):\n",
    "            result[i] += data[i + j] * vector[j]\n",
    "\n",
    "    return result\n",
    "\n",
    "def autoregressive_component_vectorized(data, lags, vector):\n",
    "\n",
    "    # Create an empty matrix with the appropriate dimensions\n",
    "    rows = len(data)\n",
    "    lagged_matrix = np.zeros((rows, lags + 1))\n",
    "\n",
    "    # Loop over number of lags and roll data \n",
    "    for i in range(lags + 1):\n",
    "        lagged_matrix[:, i] = np.roll(data, -i)\n",
    "\n",
    "    # Remove rows with incomplete data\n",
    "    lagged_matrix = lagged_matrix[:rows - lags]\n",
    "\n",
    "    result = np.matmul(lagged_matrix, vector)\n",
    "    return result\n",
    "\n",
    "\n",
    "#####\n",
    "# Integrated Component\n",
    "\n",
    "def integrated_component_basic(data, order):\n",
    "\n",
    "    differenced_data = data.copy()\n",
    "    for _ in range(order):\n",
    "        differenced_data = [differenced_data[i] - differenced_data[i - 1] for i in range(1, len(differenced_data))]\n",
    "    return np.array(differenced_data)\n",
    "\n",
    "\n",
    "def integrated_component_vectorized(data, order):\n",
    "\n",
    "    differenced_data = np.diff(data, n=order)\n",
    "    return differenced_data\n",
    "\n",
    "\n",
    "#####\n",
    "# Moving Average Component\n",
    "\n",
    "def moving_average_component_basic(original_data, forecast_data, order, theta):\n",
    "\n",
    "    original_data = np.array(original_data)\n",
    "    forecast_data = np.array(forecast_data)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    min_length = min(len(original_data), len(forecast_data))\n",
    "    original_data = original_data[:min_length]\n",
    "    forecast_data = forecast_data[:min_length]\n",
    "\n",
    "    errors = original_data - forecast_data\n",
    "    updated_forecast = forecast_data.copy()\n",
    "\n",
    "    for t in range(order, len(errors)):\n",
    "        weighted_sum = 0\n",
    "        for i in range(1, order + 1):\n",
    "            weighted_sum += theta[i - 1] * errors[t - i]\n",
    "        updated_forecast[t] += weighted_sum\n",
    "\n",
    "    return updated_forecast\n",
    "\n",
    "\n",
    "def moving_average_component_vectorized(original_data, forecast_data, order, theta):\n",
    "\n",
    "    original_data = np.array(original_data)\n",
    "    forecast_data = np.array(forecast_data)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    # Ensure the lengths of original_data and forecast_data are the same\n",
    "    min_length = min(len(original_data), len(forecast_data))\n",
    "    original_data = original_data[:min_length]\n",
    "    forecast_data = forecast_data[:min_length]\n",
    "\n",
    "    # Calculate the errors\n",
    "    errors = original_data - forecast_data\n",
    "    \n",
    "    # Create a matrix of lagged errors\n",
    "    lagged_errors = np.zeros((order, len(errors)))\n",
    "    # loop over MA order \n",
    "    for i in range(1, order + 1):\n",
    "        lagged_errors[i - 1, i:] = errors[:-i]\n",
    "    \n",
    "    # Calculate the weighted sum of lagged errors\n",
    "    weighted_lagged_errors = np.matmul(theta, lagged_errors)\n",
    "    \n",
    "    # Update the forecast\n",
    "    updated_forecast = forecast_data + weighted_lagged_errors\n",
    "    \n",
    "    return updated_forecast\n",
    "\n",
    "\n",
    "def moving_average_component_vectorized_v2(actual, forecast, order, theta):\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    forecast = np.array(forecast)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    # Ensure the lengths of actual and forecast are the same\n",
    "    min_length = min(len(actual), len(forecast))\n",
    "    actual = actual[:min_length]\n",
    "    forecast = forecast[:min_length]\n",
    "    \n",
    "    # Calculate the errors\n",
    "    errors = actual - forecast\n",
    "    \n",
    "    # Adjust for errors from AR component\n",
    "    lagged_errors = np.zeros((order, len(errors)))\n",
    "    for i in range(1, order + 1):\n",
    "        lagged_errors[i - 1, i:] = errors[:-i]\n",
    "    weighted_lagged_errors = np.dot(theta, lagged_errors)\n",
    "    updated_forecast = forecast + weighted_lagged_errors\n",
    "    \n",
    "    # Adjust for errors from own MA component\n",
    "    updated_errors = actual - updated_forecast # TODO: Oder forecast - updated forecast\n",
    "    lagged_updated_errors = np.zeros((order, len(updated_errors)))\n",
    "    for i in range(1, order + 1):\n",
    "        lagged_updated_errors[i - 1, i:] = updated_errors[:-i]\n",
    "    weighted_updated_errors = np.dot(theta, lagged_updated_errors)\n",
    "    updated_forecast += weighted_updated_errors\n",
    "    \n",
    "    return updated_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_a: FAILED\n",
      "-2.707527627339375\n",
      "execution time: 234.01925683021545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#def test_arima_complete_basic_dataset_a():\n",
    "start_time = time.time()\n",
    "integrated_data = integrated_component_basic(data_a, order)\n",
    "forecast_data = autoregressive_component_basic(integrated_data, lags, vector)\n",
    "result = moving_average_component_basic(integrated_data[(lags + 1):], forecast_data, lags, theta)\n",
    "last_result_a = result[-1]\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "if abs(last_result_a - expected_output_complete_a) < 0.00005:\n",
    "    print(\"test_arima_complete_basic_dataset_a: PASSED:\", last_result_a)\n",
    "    print(\"execution time:\", execution_time)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_a: FAILED\")\n",
    "    print(last_result_a)\n",
    "    print(\"execution time:\", execution_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.707527627339375\n",
      "test_arima_complete_vectorized_dataset_a: FAILED\n",
      "-2.707527627339375\n",
      "execution time: 8.695611953735352\n"
     ]
    }
   ],
   "source": [
    "#def test_arima_complete_vectorized_dataset_a():\n",
    "start_time = time.time()\n",
    "integrated_data = integrated_component_vectorized(data_a, order)\n",
    "forecast_data = autoregressive_component_vectorized(integrated_data, lags, vector)\n",
    "result = moving_average_component_vectorized(integrated_data[(lags + 1):], forecast_data, lags, theta)\n",
    "last_result_a = result[-1]\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(last_result_a)\n",
    "if abs(last_result_a - expected_output_complete_a) < 0.00005:\n",
    "    print(\"test_arima_complete_vectorized_dataset_a: PASSED:\", last_result_a)\n",
    "    print(\"execution time:\", execution_time)\n",
    "else:\n",
    "    print(\"test_arima_complete_vectorized_dataset_a: FAILED\")\n",
    "    print(last_result_a)\n",
    "    print(\"execution time:\", execution_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_b: FAILED\n",
      "293.16202999999996\n",
      "execution time: 168.16781091690063\n"
     ]
    }
   ],
   "source": [
    "# Dataset B\n",
    "start_time = time.time()\n",
    "integrated_data_b = integrated_component_basic(data_b, order)\n",
    "forecast_data_b = autoregressive_component_basic(integrated_data_b, lags, vector)\n",
    "result_b = moving_average_component_basic(integrated_data_b[(lags + 1):], forecast_data_b, lags, theta)\n",
    "last_result_b = result_b[-1]\n",
    "end_time = time.time()\n",
    "execution_time_b = end_time - start_time\n",
    "if abs(last_result_b - expected_output_complete_b) < 0.00005:\n",
    "    print(\"test_arima_complete_basic_dataset_b: PASSED:\", last_result_b)\n",
    "    print(\"execution time:\", execution_time_b)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_b: FAILED\")\n",
    "    print(last_result_b)\n",
    "    print(\"execution time:\", execution_time_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.16202999999996\n",
      "test_arima_complete_vectorized_dataset_b: FAILED\n",
      "293.16202999999996\n",
      "execution time: 5.534387826919556\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "integrated_data_b = integrated_component_vectorized(data_b, order)\n",
    "forecast_data_b = autoregressive_component_vectorized(integrated_data_b, lags, vector)\n",
    "result_b = moving_average_component_vectorized(integrated_data_b[(lags + 1):], forecast_data_b, lags, theta)\n",
    "last_result_b = result_b[-1]\n",
    "end_time = time.time()\n",
    "execution_time_b = end_time - start_time\n",
    "print(last_result_b)\n",
    "if abs(last_result_b - expected_output_complete_b) < 0.00005:\n",
    "    print(\"test_arima_complete_vectorized_dataset_b: PASSED:\", last_result_b)\n",
    "    print(\"execution time:\", execution_time_b)\n",
    "else:\n",
    "    print(\"test_arima_complete_vectorized_dataset_b: FAILED\")\n",
    "    print(last_result_b)\n",
    "    print(\"execution time:\", execution_time_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_c: FAILED\n",
      "-6.40901\n",
      "execution time: 329.0239520072937\n"
     ]
    }
   ],
   "source": [
    "# Dataset C\n",
    "start_time = time.time()\n",
    "integrated_data_c = integrated_component_basic(data_c, order)\n",
    "forecast_data_c = autoregressive_component_basic(integrated_data_c, lags, vector)\n",
    "result_c = moving_average_component_basic(integrated_data_c[(lags + 1):], forecast_data_c, lags, theta)\n",
    "last_result_c = result_c[-1]\n",
    "end_time = time.time()\n",
    "execution_time_c = end_time - start_time\n",
    "if abs(last_result_c - expected_output_complete_c) < 0.00005:\n",
    "    print(\"test_arima_complete_basic_dataset_c: PASSED:\", last_result_c)\n",
    "    print(\"execution time:\", execution_time_c)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_c: FAILED\")\n",
    "    print(last_result_c)\n",
    "    print(\"execution time:\", execution_time_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.40901\n",
      "test_arima_complete_vectorized_dataset_c: FAILED\n",
      "-6.40901\n",
      "execution time: 12.904079675674438\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "integrated_data_c = integrated_component_vectorized(data_c, order)\n",
    "forecast_data_c = autoregressive_component_vectorized(integrated_data_c, lags, vector)\n",
    "result_c = moving_average_component_vectorized(integrated_data_c[(lags + 1):], forecast_data_c, lags, theta)\n",
    "last_result_c = result_c[-1]\n",
    "end_time = time.time()\n",
    "execution_time_c = end_time - start_time\n",
    "print(last_result_c)\n",
    "if abs(last_result_c - expected_output_complete_c) < 0.00005:\n",
    "    print(\"test_arima_complete_vectorized_dataset_c: PASSED:\", last_result_c)\n",
    "    print(\"execution time:\", execution_time_c)\n",
    "else:\n",
    "    print(\"test_arima_complete_vectorized_dataset_c: FAILED\")\n",
    "    print(last_result_c)\n",
    "    print(\"execution time:\", execution_time_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_d: FAILED\n",
      "-1.7463627392938856\n",
      "execution time: 107.31236505508423\n"
     ]
    }
   ],
   "source": [
    "# Dataset D\n",
    "start_time = time.time()\n",
    "integrated_data_d = integrated_component_basic(data_d, order)\n",
    "forecast_data_d = autoregressive_component_basic(integrated_data_d, lags, vector)\n",
    "result_d = moving_average_component_basic(integrated_data_d[(lags + 1):], forecast_data_d, lags, theta)\n",
    "last_result_d = result_d[-1]\n",
    "end_time = time.time()\n",
    "execution_time_d = end_time - start_time\n",
    "if abs(last_result_d - expected_output_complete_d) < 0.00005:\n",
    "    print(\"test_arima_complete_basic_dataset_d: PASSED:\", last_result_d)\n",
    "    print(\"execution time:\", execution_time_d)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_d: FAILED\")\n",
    "    print(last_result_d)\n",
    "    print(\"execution time:\", execution_time_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7463627392938856\n",
      "test_arima_complete_vectorized_dataset_d: FAILED\n",
      "-1.7463627392938856\n",
      "execution time: 2.063900947570801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "integrated_data_d = integrated_component_vectorized(data_d, order)\n",
    "forecast_data_d = autoregressive_component_vectorized(integrated_data_d, lags, vector)\n",
    "result_d = moving_average_component_vectorized(integrated_data_d[(lags + 1):], forecast_data_d, lags, theta)\n",
    "last_result_d = result_d[-1]\n",
    "end_time = time.time()\n",
    "execution_time_d = end_time - start_time\n",
    "print(last_result_d)\n",
    "if abs(last_result_d - expected_output_complete_d) < 0.00005:\n",
    "    print(\"test_arima_complete_vectorized_dataset_d: PASSED:\", last_result_d)\n",
    "    print(\"execution time:\", execution_time_d)\n",
    "else:\n",
    "    print(\"test_arima_complete_vectorized_dataset_d: FAILED\")\n",
    "    print(last_result_d)\n",
    "    print(\"execution time:\", execution_time_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_e: FAILED\n",
      "-2.5949976000000037\n",
      "execution time: 61.96626114845276\n"
     ]
    }
   ],
   "source": [
    "# Dataset E\n",
    "start_time = time.time()\n",
    "integrated_data_e = integrated_component_basic(data_e, order)\n",
    "forecast_data_e = autoregressive_component_basic(integrated_data_e, lags, vector)\n",
    "result_e = moving_average_component_basic(integrated_data_e[(lags + 1):], forecast_data_e, lags, theta)\n",
    "last_result_e = result_e[-1]\n",
    "end_time = time.time()\n",
    "execution_time_e = end_time - start_time\n",
    "if abs(last_result_e - expected_output_complete_e) < 0.00005:\n",
    "    print(\"test_arima_complete_basic_dataset_e: PASSED:\", last_result_e)\n",
    "    print(\"execution time:\", execution_time_e)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_e: FAILED\")\n",
    "    print(last_result_e)\n",
    "    print(\"execution time:\", execution_time_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_e: FAILED\n",
      "-2.5949976000000037\n",
      "execution time: 45.764225006103516\n"
     ]
    }
   ],
   "source": [
    "# Dataset E v2\n",
    "start_time = time.time()\n",
    "integrated_data_e = integrated_component_basic(data_e, order)\n",
    "forecast_data_e = autoregressive_component_basic_v2(integrated_data_e, lags, vector)\n",
    "result_e = moving_average_component_basic(integrated_data_e[(lags + 1):], forecast_data_e, lags, theta)\n",
    "last_result_e = result_e[-1]\n",
    "end_time = time.time()\n",
    "execution_time_e = end_time - start_time\n",
    "if abs(last_result_e - expected_output_complete_e) < 0.00005:\n",
    "    print(\"test_arima_complete_basic_dataset_e: PASSED:\", last_result_e)\n",
    "    print(\"execution time:\", execution_time_e)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_e: FAILED\")\n",
    "    print(last_result_e)\n",
    "    print(\"execution time:\", execution_time_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.5949976000000037\n",
      "test_arima_complete_vectorized_dataset_e: FAILED\n",
      "-2.5949976000000037\n",
      "execution time: 1.5847039222717285\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "integrated_data_e = integrated_component_vectorized(data_e, order)\n",
    "forecast_data_e = autoregressive_component_vectorized(integrated_data_e, lags, vector)\n",
    "result_e = moving_average_component_vectorized(integrated_data_e[(lags + 1):], forecast_data_e, lags, theta)\n",
    "last_result_e = result_e[-1]\n",
    "end_time = time.time()\n",
    "execution_time_e = end_time - start_time\n",
    "print(last_result_e)\n",
    "if abs(last_result_e - expected_output_complete_e) < 0.00005:\n",
    "    print(\"test_arima_complete_vectorized_dataset_e: PASSED:\", last_result_e)\n",
    "    print(\"execution time:\", execution_time_e)\n",
    "else:\n",
    "    print(\"test_arima_complete_vectorized_dataset_e: FAILED\")\n",
    "    print(last_result_e)\n",
    "    print(\"execution time:\", execution_time_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_f: FAILED\n",
      "721.2226800000001\n",
      "execution time: 284.3350999355316\n"
     ]
    }
   ],
   "source": [
    "# Dataset F\n",
    "start_time = time.time()\n",
    "integrated_data_f = integrated_component_basic(data_f, order)\n",
    "forecast_data_f = autoregressive_component_basic(integrated_data_f, lags, vector)\n",
    "result_f = moving_average_component_basic(integrated_data_f[(lags + 1):], forecast_data_f, lags, theta)\n",
    "last_result_f = result_f[-1]\n",
    "end_time = time.time()\n",
    "execution_time_f = end_time - start_time\n",
    "if abs(last_result_f - expected_output_complete_f) < 0.005:\n",
    "    print(\"test_arima_complete_basic_dataset_f: PASSED:\", last_result_f)\n",
    "    print(\"execution time:\", execution_time_f)\n",
    "else:\n",
    "    print(\"test_arima_complete_basic_dataset_f: FAILED\")\n",
    "    print(last_result_f)\n",
    "    print(\"execution time:\", execution_time_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721.2226800000001\n",
      "test_arima_complete_vectorized_dataset_f: FAILED\n",
      "721.2226800000001\n",
      "execution time: 9.943871259689331\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "integrated_data_f = integrated_component_vectorized(data_f, order)\n",
    "forecast_data_f = autoregressive_component_vectorized(integrated_data_f, lags, vector)\n",
    "result_f = moving_average_component_vectorized(integrated_data_f[(lags + 1):], forecast_data_f, lags, theta)\n",
    "last_result_f = result_f[-1]\n",
    "end_time = time.time()\n",
    "execution_time_f = end_time - start_time\n",
    "print(last_result_f)\n",
    "if abs(last_result_f - expected_output_complete_f) < 0.005:\n",
    "    print(\"test_arima_complete_vectorized_dataset_f: PASSED:\", last_result_f)\n",
    "    print(\"execution time:\", execution_time_f)\n",
    "else:\n",
    "    print(\"test_arima_complete_vectorized_dataset_f: FAILED\")\n",
    "    print(last_result_f)\n",
    "    print(\"execution time:\", execution_time_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
