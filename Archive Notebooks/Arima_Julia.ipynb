{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moving_average_component_vectorized (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# autoregressive_component\n",
    "\n",
    "function autoregressive_component_basic(data::Vector{Float64}, lags::Int, vector::Vector{Float64})\n",
    "    rows = length(data)\n",
    "    lagged_matrix = zeros(Float64, rows, lags + 1)\n",
    "    \n",
    "    for i in 0:lags\n",
    "        for j in 1:rows\n",
    "            if j + i <= rows\n",
    "                lagged_matrix[j, i + 1] = data[j + i]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    lagged_matrix = lagged_matrix[1:(rows - lags), :]\n",
    "    \n",
    "    result = zeros(Float64, size(lagged_matrix, 1))\n",
    "    for i in 1:size(lagged_matrix, 1)\n",
    "        for j in 1:length(vector)\n",
    "            result[i] += lagged_matrix[i, j] * vector[j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return result\n",
    "end\n",
    "\n",
    "\n",
    "function autoregressive_component_vectorized(data::Vector{Float64}, lags::Int, vector::Vector{Float64})\n",
    "    rows = length(data)\n",
    "    lagged_matrix = zeros(Float64, rows, lags + 1)\n",
    "    \n",
    "    for i in 0:lags\n",
    "        lagged_matrix[:, i + 1] = circshift(data, -i)\n",
    "    end\n",
    "    \n",
    "    # Remove rows with incomplete data\n",
    "    lagged_matrix = lagged_matrix[1:(rows - lags), :]\n",
    "    \n",
    "    result = lagged_matrix * vector\n",
    "    return result\n",
    "end\n",
    "\n",
    "# integrated_component\n",
    "\n",
    "function integrated_component_basic(data::Vector{Float64}, order::Int)\n",
    "    differenced_data = copy(data)\n",
    "    for _ in 1:order\n",
    "        new_data = Float64[]\n",
    "        for i in 2:length(differenced_data)\n",
    "            push!(new_data, differenced_data[i] - differenced_data[i - 1])\n",
    "        end\n",
    "        differenced_data = new_data\n",
    "    end    \n",
    "    return differenced_data\n",
    "end\n",
    "\n",
    "\n",
    "function integrated_component_vectorized(data::Vector{Float64}, order::Int)\n",
    "    differenced_data = data\n",
    "    for _ in 1:order\n",
    "        differenced_data = diff(differenced_data)\n",
    "    end    \n",
    "    return differenced_data\n",
    "end\n",
    "\n",
    "# moving_average_component\n",
    "\n",
    "function moving_average_component_basic(original_data::Vector{Float64}, forecast_data::Vector{Float64}, order::Int, theta::Vector{Float64})\n",
    "    min_length = min(length(original_data), length(forecast_data))\n",
    "    original_data = original_data[1:min_length]\n",
    "    forecast_data = forecast_data[1:min_length]\n",
    "    \n",
    "    errors = original_data - forecast_data\n",
    "    updated_forecast = copy(forecast_data)\n",
    "    \n",
    "    for t in (order + 1):length(errors)\n",
    "        weighted_sum = 0.0\n",
    "        for i in 1:order\n",
    "            weighted_sum += theta[i] * errors[t - i]\n",
    "        end\n",
    "        updated_forecast[t] += weighted_sum\n",
    "    end\n",
    "    \n",
    "    return updated_forecast\n",
    "end\n",
    "\n",
    "\n",
    "function moving_average_component_vectorized(original_data::Vector{Float64}, forecast_data::Vector{Float64}, order::Int, theta::Vector{Float64})\n",
    "    min_length = min(length(original_data), length(forecast_data))\n",
    "    original_data = original_data[1:min_length]\n",
    "    forecast_data = forecast_data[1:min_length]\n",
    "    \n",
    "    errors = original_data - forecast_data\n",
    "    lagged_errors = zeros(Float64, order, length(errors))\n",
    "    \n",
    "    for i in 1:order\n",
    "        lagged_errors[i, (i + 1):end] = errors[1:(end - i)]\n",
    "    end\n",
    "    \n",
    "    weighted_lagged_errors = theta' * lagged_errors\n",
    "    \n",
    "    updated_forecast = forecast_data .+ weighted_lagged_errors\n",
    "    return updated_forecast\n",
    "end\n",
    "\n",
    "\n",
    "# function moving_average_component_vectorized(original_data::Vector{Float64}, forecast_data::Vector{Float64}, order::Int, theta::Vector{Float64})\n",
    "#     min_length = min(length(original_data), length(forecast_data))\n",
    "#     original_data = original_data[1:min_length]\n",
    "#     forecast_data = forecast_data[1:min_length]\n",
    "\n",
    "#     # Adjust for errors from AR component\n",
    "#     errors = original_data - forecast_data\n",
    "#     lagged_errors = zeros(Float64, order, length(errors))\n",
    "#     for i in 1:order\n",
    "#         lagged_errors[i, (i + 1):end] = errors[1:(end - i)]\n",
    "#     end\n",
    "#     weighted_lagged_errors = theta' * lagged_errors\n",
    "#     updated_forecast = forecast_data .+ weighted_lagged_errors\n",
    "\n",
    "#     # Adjust for errors from own MA component\n",
    "#     updated_errors = forecast_data - updated_forecast\n",
    "#     lagged_updated_errors = zeros(Float64, order, length(updated_errors))\n",
    "#     for i in 1:order\n",
    "#         lagged_updated_errors[i, (i + 1):end] = updated_errors[1:(end - i)]\n",
    "#     end\n",
    "#     weighted_updated_errors = theta' * lagged_updated_errors\n",
    "#     updated_forecast .+= weighted_updated_errors\n",
    "\n",
    "#     return updated_forecast\n",
    "# end\n",
    "\n",
    "\n",
    "# function moving_average_component_vectorized(original_data::Vector{Float64}, forecast_data::Vector{Float64}, order::Int, theta::Vector{Float64})\n",
    "#     min_length = min(length(original_data), length(forecast_data))\n",
    "#     original_data = original_data[1:min_length]\n",
    "#     forecast_data = forecast_data[1:min_length]\n",
    "\n",
    "#     # Adjust for errors from AR component\n",
    "#     errors = original_data - forecast_data\n",
    "#     lagged_errors = zeros(Float64, order, min_length)\n",
    "#     for i in 1:order\n",
    "#         lagged_errors[i, (i + 1):end] .= errors[1:(end - i)]\n",
    "#     end\n",
    "#     weighted_lagged_errors = theta' * lagged_errors\n",
    "#     updated_forecast = forecast_data .+ weighted_lagged_errors\n",
    "\n",
    "#     # Adjust for errors from own MA component\n",
    "#     updated_errors = forecast_data .- updated_forecast\n",
    "#     lagged_updated_errors = zeros(Float64, order, min_length)\n",
    "#     for i in 1:order\n",
    "#         lagged_updated_errors[i, (i + 1):end] .= updated_errors[1:(end - i)]\n",
    "#     end\n",
    "#     weighted_updated_errors = theta' * lagged_updated_errors\n",
    "#     updated_forecast .+= weighted_updated_errors\n",
    "\n",
    "#     return updated_forecast\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1143.753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# data_a = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv\", DataFrame)[:, 1]\n",
    "# data_b = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/energy_generation_solar.csv\", DataFrame)[:, 1]\n",
    "# data_c = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/heart_rate.csv\", DataFrame)[:, 1]\n",
    "# data_d = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/temperature_delhi.csv\", DataFrame)[:, 1]\n",
    "# data_e = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/stock_open_microsoft.csv\", DataFrame)[:, 1]\n",
    "# data_f = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/nyctaxitraffic.csv\", DataFrame)[:, 1]\n",
    "\n",
    "# Define the parameters for testing\n",
    "lags = 1\n",
    "vector = [0.9208, -0.0111]\n",
    "order = 0\n",
    "theta = [0.3]\n",
    "\n",
    "# Expected outputs\n",
    "expected_output_ar_a = 8.42711736\n",
    "expected_output_integrated_a = 0.55796623\n",
    "expected_output_ma_a = 8.25047461\n",
    "expected_output_complete_a = 3.059677\n",
    "\n",
    "expected_output_ar_b = 33.09027077\n",
    "expected_output_integrated_b = 1.23456789\n",
    "expected_output_ma_b = 33.56789012\n",
    "expected_output_complete_b = 61.78846\n",
    "\n",
    "expected_output_ar_c = 98.77752695\n",
    "expected_output_integrated_c = 2.34567890\n",
    "expected_output_ma_c = 99.12345678\n",
    "expected_output_complete_c = -6.16423\n",
    "\n",
    "expected_output_complete_d = -1.066503\n",
    "\n",
    "expected_output_complete_e = 6.920413\n",
    "\n",
    "expected_output_complete_f = 1143.753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_a: PASSED: 3.0596765181255368\n",
      "execution time:5.808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#function test_arima_complete_basic_dataset_a()\n",
    "    start_time = now()\n",
    "    integrated_data = integrated_component_basic(data_a, order)\n",
    "    forecast_data = autoregressive_component_basic(integrated_data, lags, vector)\n",
    "    result = moving_average_component_basic(integrated_data[lags + 1:end], forecast_data, lags, theta)\n",
    "    last_result_a = result[end]\n",
    "    end_time = now()\n",
    "    execution_time = Dates.value(end_time - start_time) / 1000\n",
    "    if abs(last_result_a - expected_output_complete_a) < 0.00005\n",
    "      println(\"test_arima_complete_basic_dataset_a: PASSED: \", last_result_a)\n",
    "      println(\"execution time:\", execution_time)\n",
    "      return true\n",
    "    else\n",
    "      println(\"test_arima_complete_basic_dataset_a: FAILED\")\n",
    "      println(last_result_a)\n",
    "      return false\n",
    "    end\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "OutOfMemoryError()",
     "output_type": "error",
     "traceback": [
      "OutOfMemoryError()\n",
      "\n",
      "Stacktrace:\n",
      "  [1] Array\n",
      "    @ ./boot.jl:479 [inlined]\n",
      "  [2] Array\n",
      "    @ ./boot.jl:487 [inlined]\n",
      "  [3] Array\n",
      "    @ ./boot.jl:494 [inlined]\n",
      "  [4] similar\n",
      "    @ ./abstractarray.jl:877 [inlined]\n",
      "  [5] similar\n",
      "    @ ./abstractarray.jl:876 [inlined]\n",
      "  [6] similar\n",
      "    @ ./broadcast.jl:224 [inlined]\n",
      "  [7] similar\n",
      "    @ ./broadcast.jl:223 [inlined]\n",
      "  [8] copy\n",
      "    @ ./broadcast.jl:928 [inlined]\n",
      "  [9] materialize\n",
      "    @ ./broadcast.jl:903 [inlined]\n",
      " [10] moving_average_component_vectorized(original_data::Vector{Float64}, forecast_data::Vector{Float64}, order::Int64, theta::Vector{Float64})\n",
      "    @ Main ~/Documents/GitHub/MasterThesis/Archive Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W0sZmlsZQ==.jl:102\n",
      " [11] top-level scope\n",
      "    @ ~/Documents/GitHub/MasterThesis/Archive Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sZmlsZQ==.jl:5"
     ]
    }
   ],
   "source": [
    "#function test_arima_complete_vectorized_dataset_a()\n",
    "    start_time = now()\n",
    "    integrated_data = integrated_component_vectorized(data_a, order)\n",
    "    forecast_data = autoregressive_component_vectorized(integrated_data, lags, vector)\n",
    "    result = moving_average_component_vectorized(integrated_data[lags + 1:end], forecast_data, lags, theta)\n",
    "    last_result_a = result[end, end]\n",
    "    end_time = now()\n",
    "    execution_time = Dates.value(end_time - start_time) / 1000\n",
    "    println(last_result_a)\n",
    "    if abs(last_result_a - expected_output_complete_a) < 0.00005\n",
    "        println(\"test_arima_complete_vectorized_dataset_d: PASSED: \", last_result_a)\n",
    "        println(\"execution time:\", execution_time)\n",
    "        return true\n",
    "    else\n",
    "        println(\"test_arima_complete_vectorized_dataset_a: FAILED\")\n",
    "        println(last_result_a)\n",
    "        return false\n",
    "    end\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_arima_complete_basic_dataset_f: FAILED\n",
      "24715.20587\n",
      "execution time:5.432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_f = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/nyctaxitraffic.csv\", DataFrame)[:, 1]\n",
    "\n",
    "\n",
    "#function test_arima_complete_basic_dataset_f()\n",
    "    start_time = now()\n",
    "    integrated_data = integrated_component_basic(data_f, order)\n",
    "    forecast_data = autoregressive_component_basic(integrated_data, lags, vector)\n",
    "    result = moving_average_component_basic(integrated_data[lags + 1:end], forecast_data, lags, theta)\n",
    "    last_result_f = result[end]\n",
    "    end_time = now()\n",
    "    execution_time = Dates.value(end_time - start_time) / 1000\n",
    "    if abs(last_result_f - expected_output_complete_f) < 0.005\n",
    "      println(\"test_arima_complete_basic_dataset_f: PASSED: \", last_result_f)\n",
    "      println(\"execution time:\", execution_time)\n",
    "      return true\n",
    "    else\n",
    "      println(\"test_arima_complete_basic_dataset_f: FAILED\")\n",
    "      println(last_result_f)\n",
    "      println(\"execution time:\", execution_time)\n",
    "      return false\n",
    "    end\n",
    "#  end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "OutOfMemoryError()",
     "output_type": "error",
     "traceback": [
      "OutOfMemoryError()\n",
      "\n",
      "Stacktrace:\n",
      "  [1] Array\n",
      "    @ ./boot.jl:479 [inlined]\n",
      "  [2] Array\n",
      "    @ ./boot.jl:487 [inlined]\n",
      "  [3] Array\n",
      "    @ ./boot.jl:494 [inlined]\n",
      "  [4] similar\n",
      "    @ ./abstractarray.jl:877 [inlined]\n",
      "  [5] similar\n",
      "    @ ./abstractarray.jl:876 [inlined]\n",
      "  [6] similar\n",
      "    @ ./broadcast.jl:224 [inlined]\n",
      "  [7] similar\n",
      "    @ ./broadcast.jl:223 [inlined]\n",
      "  [8] copy\n",
      "    @ ./broadcast.jl:928 [inlined]\n",
      "  [9] materialize\n",
      "    @ ./broadcast.jl:903 [inlined]\n",
      " [10] moving_average_component_vectorized(original_data::Vector{Float64}, forecast_data::Vector{Float64}, order::Int64, theta::Vector{Float64})\n",
      "    @ Main ~/Documents/GitHub/MasterThesis/Archive Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W0sZmlsZQ==.jl:102\n",
      " [11] top-level scope\n",
      "    @ ~/Documents/GitHub/MasterThesis/Archive Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:6"
     ]
    }
   ],
   "source": [
    "  \n",
    "  #function test_arima_complete_vectorized_dataset_f()\n",
    "    start_time = now()\n",
    "    integrated_data = integrated_component_vectorized(data_f, order)\n",
    "    forecast_data = autoregressive_component_vectorized(integrated_data, lags, vector)\n",
    "    result = moving_average_component_vectorized(integrated_data[lags + 1:end], forecast_data, lags, theta)\n",
    "    last_result_f = result[end, end]\n",
    "    end_time = now()\n",
    "    execution_time = Dates.value(end_time - start_time) / 1000\n",
    "    println(last_result_f)\n",
    "    if abs(last_result_f - expected_output_complete_f) < 0.005\n",
    "      println(\"test_arima_complete_vectorized_dataset_f: PASSED: \", last_result_f)\n",
    "      println(\"execution time:\", execution_time)\n",
    "      return true\n",
    "    else\n",
    "      println(\"test_arima_complete_vectorized_dataset_f: FAILED\")\n",
    "      println(last_result_f)\n",
    "      return false\n",
    "    end\n",
    "  #end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
