{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Smoothing: Julia \n",
    "First experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "import Pkg\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"BenchmarkTools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## Dataset Wind Turbine: Wind Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/berkerisen/wind-turbine-scada-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe wind_speed has 25265000 rows.\n"
     ]
    }
   ],
   "source": [
    "#read in the time series data \n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "df = CSV.read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/wind_turbine_scada.csv\", DataFrame)\n",
    "\n",
    "wind_speed = df[!, 3]\n",
    "wind_speed = filter(!ismissing, wind_speed)\n",
    "\n",
    "# Replication factor\n",
    "factor = 500\n",
    "\n",
    "# Replicate the wind_speed array\n",
    "wind_speed = repeat(wind_speed, factor)\n",
    "\n",
    "println(\"Dataframe wind_speed has \", size(wind_speed, 1), \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #1 Basic For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset wind_speed\n",
      "### #1 Basic For Loop \n",
      "\n",
      "The last smoothed value for wind_speed is: 9.729056156830051\n",
      "The function was executed in 8.852018594741821 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with wind_speed data\n",
    "#wind_speed = Float64.(wind_speed)\n",
    "data_a = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv\", DataFrame)[:, 1]\n",
    "wind_speed = data_a\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = wind_speed[1]\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for j in 2:length(wind_speed)\n",
    "        smoothed_value = alpha * wind_speed[j] + (1 - alpha) * smoothed_value\n",
    "    end\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset wind_speed\")\n",
    "println(\"### #1 Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for wind_speed is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset wind_speed\n",
      "### #1 Basic For Loop \n",
      "\n",
      "The last smoothed value for wind_speed is: 9.729056156830051\n",
      "The function was executed in 9.903814554214478 seconds\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. \n",
      "\u001b[1;31mBitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. \n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. \n",
      "\u001b[1;31mWeitere Informationen finden Sie unter Jupyter <a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with wind_speed data\n",
    "#wind_speed = Float64.(wind_speed)\n",
    "data_a = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv\", DataFrame)[:, 1]\n",
    "wind_speed = data_a\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = wind_speed[1]\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for j in 2:length(wind_speed)\n",
    "        smoothed_value = alpha * wind_speed[j] + (1 - alpha) * smoothed_value\n",
    "    end\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset wind_speed\")\n",
    "println(\"### #1 Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for wind_speed is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #2 Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset wind_speed\n",
      "### #2 Vectorized \n",
      "\n",
      "The last smoothed value for wind_speed is: 9.729056156830051\n",
      "The function was executed in 4.238531470298767 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with wind_speed data\n",
    "#wind_speed = Float64.(wind_speed)\n",
    "data_a = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv\", DataFrame)[:, 1]\n",
    "wind_speed = data_a\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing\n",
    "    weights = alpha .* (1 - alpha) .^ (length(wind_speed)-1:-1:0)\n",
    "    smoothed_values = cumsum(weights .* wind_speed) ./ cumsum(weights)\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset wind_speed\")\n",
    "println(\"### #2 Vectorized \\n\")\n",
    "println(\"The last smoothed value for wind_speed is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #3 Parallelized Basic For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 8\n",
      "### Dataset wind_speed\n",
      "### #3 Parallelized Basic For Loop \n",
      "\n",
      "The last smoothed value for wind_speed is: 9.729056156830051\n",
      "The function was executed in 9.327313899993896 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "Threads.nthreads() = 8\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with wind_speed data\n",
    "#wind_speed = Float64.(wind_speed)\n",
    "data_a = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv\", DataFrame)[:, 1]\n",
    "wind_speed = data_a\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = wind_speed[1]\n",
    "\n",
    "    # Create an array to hold the intermediate smoothed values for each thread\n",
    "    smoothed_values = fill(smoothed_value, length(wind_speed))\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    Threads.@threads for j in 2:length(wind_speed)\n",
    "        smoothed_values[j] = alpha * wind_speed[j] + (1 - alpha) * smoothed_values[j-1]\n",
    "    end\n",
    "\n",
    "    # The last smoothed value is the last element of the smoothed_values array\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset wind_speed\")\n",
    "println(\"### #3 Parallelized Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for wind_speed is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #4 Parallelized Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 8\n",
      "### Dataset wind_speed\n",
      "### #4 Vectorized \n",
      "\n",
      "The last smoothed value for wind_speed is: 9.729056156830051\n",
      "The function was executed in 3.8098859786987305 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "Threads.nthreads() = 8\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with wind_speed data\n",
    "#wind_speed = Float64.(wind_speed)\n",
    "data_a = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/wind_speed.csv\", DataFrame)[:, 1]\n",
    "wind_speed = data_a\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing\n",
    "    weights = alpha .* (1 - alpha) .^ (length(wind_speed)-1:-1:0)\n",
    "    smoothed_values = cumsum(weights .* wind_speed) ./ cumsum(weights)\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset wind_speed\")\n",
    "println(\"### #4 Vectorized \\n\")\n",
    "println(\"The last smoothed value for wind_speed is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## Dataset: Solar Energy Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe column_generation_solar has 49064400 rows.\n"
     ]
    }
   ],
   "source": [
    "#read in the time series data \n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "df = CSV.read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/energy_dataset.csv\", DataFrame, missingstring=\" \", silencewarnings=true, types=Dict(19 => Float64))\n",
    "\n",
    "column_generation_solar = df[!, 19]\n",
    "column_generation_solar = filter(!ismissing, column_generation_solar)\n",
    "\n",
    "# Replication factor\n",
    "factor = 1400\n",
    "\n",
    "# Replicate the wind_speed array\n",
    "column_generation_solar = repeat(column_generation_solar, factor)\n",
    "\n",
    "println(\"Dataframe column_generation_solar has \", size(column_generation_solar, 1), \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #1 Basic For Loop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset generation_solar\n",
      "### #1 Basic For Loop \n",
      "\n",
      "The last smoothed value for generation_solar is: 33.09027077319566\n",
      "The function was executed in 6.343510890007019 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with generation_solar data\n",
    "#column_generation_solar = Float64.(column_generation_solar)\n",
    "data_b = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/energy_generation_solar.csv\", DataFrame)[:, 1]\n",
    "column_generation_solar = data_b\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = column_generation_solar[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = column_generation_solar[1]\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for j in 2:length(column_generation_solar)\n",
    "        smoothed_value = alpha * column_generation_solar[j] + (1 - alpha) * smoothed_value\n",
    "    end\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = mean(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset generation_solar\")\n",
    "println(\"### #1 Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for generation_solar is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #2 Vectroized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset generation_solar\n",
      "### #2 Vectorized \n",
      "\n",
      "The last smoothed value for generation_solar is: 33.09027077319566\n",
      "The function was executed in 3.0653375148773194 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with generation_solar data\n",
    "#column_generation_solar = Float64.(column_generation_solar)\n",
    "data_b = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/energy_generation_solar.csv\", DataFrame)[:, 1]\n",
    "column_generation_solar = data_b\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = column_generation_solar[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing\n",
    "    weights = alpha .* (1 - alpha) .^ (length(column_generation_solar)-1:-1:0)\n",
    "    smoothed_values = cumsum(weights .* column_generation_solar) ./ cumsum(weights)\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = mean(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset generation_solar\")\n",
    "println(\"### #2 Vectorized \\n\")\n",
    "println(\"The last smoothed value for generation_solar is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #3 Parallelized Basic For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset generation_solar\n",
      "### #3 Parallelized Basic For Loop \n",
      "\n",
      "The last smoothed value for generation_solar is: 33.09027077319566\n",
      "The function was executed in 9.984675407409668 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "Threads.nthreads() = 8\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with column_generation_solar data\n",
    "column_generation_solar = Float64.(column_generation_solar)\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = column_generation_solar[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = column_generation_solar[1]\n",
    "\n",
    "    # Create an array to hold the intermediate smoothed values for each thread\n",
    "    smoothed_values = fill(smoothed_value, length(column_generation_solar))\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    Threads.@threads for j in 2:length(column_generation_solar)\n",
    "        smoothed_values[j] = alpha * column_generation_solar[j] + (1 - alpha) * smoothed_values[j-1]\n",
    "    end\n",
    "\n",
    "    # The last smoothed value is the last element of the smoothed_values array\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = mean(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset generation_solar\")\n",
    "println(\"### #3 Parallelized Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for generation_solar is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #4 Parallelized Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 8\n",
      "### Dataset generation_solar\n",
      "### #2 Vectorized \n",
      "\n",
      "The last smoothed value for generation_solar is: 33.09027077319566\n",
      "The function was executed in 3.0415204763412476 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "Threads.nthreads() = 8\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with generation_solar data\n",
    "#column_generation_solar = Float64.(column_generation_solar)\n",
    "data_b = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/energy_generation_solar.csv\", DataFrame)[:, 1]\n",
    "column_generation_solar = data_b\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = column_generation_solar[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing\n",
    "    weights = alpha .* (1 - alpha) .^ (length(column_generation_solar)-1:-1:0)\n",
    "    smoothed_values = cumsum(weights .* column_generation_solar) ./ cumsum(weights)\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = mean(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset generation_solar\")\n",
    "println(\"### #2 Vectorized \\n\")\n",
    "println(\"The last smoothed value for generation_solar is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## Dataset: Heart Rate Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe heart_rate_data has 103921290 rows.\n"
     ]
    }
   ],
   "source": [
    "#read in the time series data \n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "df = CSV.read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/heartrate_seconds_merged.csv\", DataFrame)\n",
    "\n",
    "heart_rate_data = df[!, 3]\n",
    "heart_rate_data = filter(!ismissing, heart_rate_data)\n",
    "\n",
    "# Replication factor\n",
    "factor = 90\n",
    "\n",
    "# Replicate the wind_speed array\n",
    "heart_rate_data = repeat(heart_rate_data, factor)\n",
    "\n",
    "println(\"Dataframe heart_rate_data has \", size(heart_rate_data, 1), \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #1 Basic Foor Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset heart_rate_data\n",
      "### #1 Basic For Loop \n",
      "\n",
      "The last smoothed value for heart_rate_data is: 26390.068709835385\n",
      "The function was executed in 11.210068345069885 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "Threads.nthreads() = 1\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with generation_solar data\n",
    "#column_generation_solar = Float64.(column_generation_solar)\n",
    "data_c = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/nyctaxitraffic.csv\", DataFrame)[:, 1]\n",
    "heart_rate_data = data_c\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = heart_rate_data[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = heart_rate_data[1]\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for j in 2:length(heart_rate_data)\n",
    "        smoothed_value = alpha * heart_rate_data[j] + (1 - alpha) * smoothed_value\n",
    "    end\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset heart_rate_data\")\n",
    "println(\"### #1 Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for heart_rate_data is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #2 Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "### Dataset heart_rate_data\n",
      "### #2 Vectorized \n",
      "\n",
      "The last smoothed value for heart_rate_data is: 26390.06870983539\n",
      "The function was executed in 5.464649558067322 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "Threads.nthreads() = 1\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with generation_solar data\n",
    "#column_generation_solar = Float64.(column_generation_solar)\n",
    "data_c = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/nyctaxitraffic.csv\", DataFrame)[:, 1]\n",
    "heart_rate_data = data_c\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = heart_rate_data[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing\n",
    "    weights = alpha .* (1 - alpha) .^ (length(heart_rate_data)-1:-1:0)\n",
    "    smoothed_values = cumsum(weights .* heart_rate_data) ./ cumsum(weights)\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset heart_rate_data\")\n",
    "println(\"### #2 Vectorized \\n\")\n",
    "println(\"The last smoothed value for heart_rate_data is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #3 Parallelized Basic For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 8\n",
      "### Dataset heart_rate_data\n",
      "### #3 Parallelized Basic For Loop \n",
      "\n",
      "The last smoothed value for heart_rate_data is: 11.475341948013103\n",
      "The function was executed in 4.837888956069946 seconds\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "Threads.nthreads() = 8\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with heart_rate_data data\n",
    "heart_rate_data = Float64.(heart_rate_data)\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 1\n",
    "execution_times = []\n",
    "smoothed_value = heart_rate_data[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Initialize the smoothed value with the first data point\n",
    "    smoothed_value = heart_rate_data[1]\n",
    "\n",
    "    # Create an array to hold the intermediate smoothed values for each thread\n",
    "    smoothed_values = fill(smoothed_value, length(heart_rate_data))\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    Threads.@threads for j in 2:length(heart_rate_data)\n",
    "        smoothed_values[j] = alpha * heart_rate_data[j] + (1 - alpha) * smoothed_values[j-1]\n",
    "    end\n",
    "\n",
    "    # The last smoothed value is the last element of the smoothed_values array\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset heart_rate_data\")\n",
    "println(\"### #3 Parallelized Basic For Loop \\n\")\n",
    "println(\"The last smoothed value for heart_rate_data is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #4 Parallelized Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 8\n",
      "### Dataset heart_rate_data\n",
      "### #4 Vectorized \n",
      "\n",
      "The last smoothed value for heart_rate_data is: 26390.06870983539\n",
      "The function was executed in 5.756901526451111 seconds\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. \n",
      "\u001b[1;31mBitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. \n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. \n",
      "\u001b[1;31mWeitere Informationen finden Sie unter Jupyter <a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "Threads.nthreads() = 8\n",
    "@show Threads.nthreads()\n",
    "\n",
    "# Julia array with generation_solar data\n",
    "#column_generation_solar = Float64.(column_generation_solar)\n",
    "data_c = CSV.read(\"/Users/niklas/Documents/GitHub/MasterThesis/0_Data_files/replicated_preprocessed_data_files/nyctaxitraffic.csv\", DataFrame)[:, 1]\n",
    "heart_rate_data = data_c\n",
    "\n",
    "# Alpha is the smoothing factor.\n",
    "alpha = 0.7\n",
    "\n",
    "# List to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = []\n",
    "smoothed_value = heart_rate_data[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for i in 1:number_of_executions\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing\n",
    "    weights = alpha .* (1 - alpha) .^ (length(heart_rate_data)-1:-1:0)\n",
    "    smoothed_values = cumsum(weights .* heart_rate_data) ./ cumsum(weights)\n",
    "    smoothed_value = smoothed_values[end]\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time()\n",
    "    push!(execution_times, end_time - start_time)\n",
    "end\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = mean(execution_times)\n",
    "\n",
    "# Print the results\n",
    "println(\"### Dataset heart_rate_data\")\n",
    "println(\"### #4 Vectorized \\n\")\n",
    "println(\"The last smoothed value for heart_rate_data is: \", smoothed_value)\n",
    "println(\"The function was executed in \", function_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "dataset_sizes =             [0.4,           0.8,             1.2,            1.6,           2.0,            2.4]\n",
    "basic_for_loop =            [0.6025749,     1.165998,        1.778749,       2.381353,      2.992056,       3.516365] \n",
    "vectorized =                [0.334854,      0.6599834,       0.9953531,      1.355899,      2.048638,       2.38394]      \n",
    "parallelized_vectorized =   [0.3317189,     0.624923,        0.9844215,      1.349854,      1.882703,       2.345044]  \n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(dataset_sizes, basic_for_loop, 'o-', label='Basic For Loop', color='blue')\n",
    "plt.plot(dataset_sizes, vectorized, 'o-', label='Vectorized', color='green')\n",
    "plt.plot(dataset_sizes, parallelized_vectorized, 'o-', label='Parallelized Vectorized', color='red')\n",
    "\n",
    "plt.xlabel('Dataset Size in GB')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('SES Execution Time Comparison for R')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(dataset_sizes)\n",
    "plt.yticks(np.arange(0, 121, 10))\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
