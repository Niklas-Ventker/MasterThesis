{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Experiments\n",
    "\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autoregressive models: AR(p)\n",
    "\n",
    "- mixed autoregressive moving average models: ARMA(p, q)\n",
    "\n",
    "- integration models: ARIMA(p, d, q)\n",
    "\n",
    "<br/>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50529,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read the data\n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "print(wind_speed.shape)\n",
    "\n",
    "initial_data = wind_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Error Metric Components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squares Error: 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_of_squares_error(original, prediction):\n",
    "    \"\"\"\n",
    "    Calculates the sum of squares error between two vectors.\n",
    "\n",
    "    Parameters:\n",
    "    original (numpy.ndarray): The original vector.\n",
    "    prediction (numpy.ndarray): The prediction vector.\n",
    "\n",
    "    Returns:\n",
    "    float: The sum of squares error.\n",
    "    \"\"\"\n",
    "    error = np.sum((original - prediction) ** 2)\n",
    "    return error\n",
    "\n",
    "# Example:\n",
    "original = np.array([1, 2, 3])\n",
    "prediction = np.array([3, 4, 5])\n",
    "error = sum_of_squares_error(original, prediction)\n",
    "print(f\"Sum of Squares Error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Autoregressive Component\n",
    "\n",
    "- **p**\n",
    "\n",
    "- This parameter represents the number of lag observations included in the model.\n",
    "- It essentially captures the relationship between an observation and a number of lagged observations (previous time steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1 Create the lagged Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50527, 3)\n",
      "[[ 5.67216682  5.2160368   5.65967417]\n",
      " [ 5.2160368   5.65967417  5.57794094]\n",
      " [ 5.65967417  5.57794094  5.60405207]\n",
      " ...\n",
      " [11.40402985  7.3326478   8.43535805]\n",
      " [ 7.3326478   8.43535805  9.42136574]\n",
      " [ 8.43535805  9.42136574  9.97933197]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_lagged_matrix(data, lags):\n",
    "    \"\"\"\n",
    "    Create a matrix with lagged data.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy array): The input data array.\n",
    "    lags (int): The number of lags.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: A matrix with the lagged data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty matrix with the appropriate dimensions\n",
    "    rows = len(data)\n",
    "    lagged_matrix = np.zeros((rows, lags + 1))\n",
    "\n",
    "    # Loop over number of lags and roll data \n",
    "    for i in range(lags + 1):\n",
    "        lagged_matrix[:, i] = np.roll(data, -i)\n",
    "\n",
    "    # Remove rows with incomplete data\n",
    "    lagged_matrix = lagged_matrix[:rows - lags]\n",
    "\n",
    "    return lagged_matrix\n",
    "\n",
    "# Example\n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(wind_speed, lags)\n",
    "print(lagged_matrix.shape)\n",
    "print(lagged_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2 Matrix Vector Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Vector Multiplication Result:\n",
      "(50527,)\n",
      "[ 5.59856424  5.16737458  5.57878322 ... 11.06558672  7.37994624\n",
      "  8.42711736]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_vector_multiplication(lagged_matrix, vector):\n",
    "    \"\"\"\n",
    "    Perform matrix-vector multiplication.\n",
    "\n",
    "    Parameters:\n",
    "    matrix (numpy array): The input matrix.\n",
    "    vector (numpy array): The vector to multiply with the matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The result of the matrix-vector multiplication.\n",
    "    \"\"\"\n",
    "    result = np.matmul(lagged_matrix, vector)\n",
    "    return result\n",
    "\n",
    "# Example \n",
    "arima_vector = np.array([0.9208, -0.0111, 0.0766])\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "print(\"Matrix Vector Multiplication Result:\")\n",
    "print(result_matrix.shape)\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3 Complete Autoregressive component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoregressive component:\n",
      "(50527,)\n",
      "[ 5.59856424  5.16737458  5.57878322 ... 11.06558672  7.37994624\n",
      "  8.42711736]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def autoregressive_component(data, lags, vector):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a matrix with lagged data.\n",
    "    Perform matrix-vector multiplication.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy array): The input data array.\n",
    "    lags (int): The number of lags.\n",
    "    vector (numpy array): The vector to multiply with the created lagged matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The result of the matrix-vector multiplication.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty matrix with the appropriate dimensions\n",
    "    rows = len(data)\n",
    "    lagged_matrix = np.zeros((rows, lags + 1))\n",
    "\n",
    "    # Loop over number of lags and roll data \n",
    "    for i in range(lags + 1):\n",
    "        lagged_matrix[:, i] = np.roll(data, -i)\n",
    "\n",
    "    # Remove rows with incomplete data\n",
    "    lagged_matrix = lagged_matrix[:rows - lags]\n",
    "\n",
    "    result = np.matmul(lagged_matrix, vector)\n",
    "    return result\n",
    "\n",
    "# Example \n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "lags = 2\n",
    "arima_vector = np.array([0.9208, -0.0111, 0.0766])\n",
    "\n",
    "result_matrix = autoregressive_component(wind_speed, lags, arima_vector)\n",
    "print(\"Autoregressive component:\")\n",
    "print(result_matrix.shape)\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## 2. Integrated Component\n",
    "\n",
    "- **d**\n",
    "\n",
    "- This parameter is the number of times that the raw observations are differenced to make the time series stationary.\n",
    "- Distribution of data is only dependent on the difference in time, not the location in time.\n",
    "- Mean and variance are constant regardless of the period you pick if data is stationary.\n",
    "- Differencing is a technique used to remove trends and seasonality from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Integrated (1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array\n",
    "array = np.array([1, 2, 4, 7, 11])\n",
    "\n",
    "# Perform differencing\n",
    "difference = np.diff(array)\n",
    "\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-39  21   1]\n"
     ]
    }
   ],
   "source": [
    "# Integrated (2)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array\n",
    "array = np.array([1, 22, 4, 7, 11])\n",
    "\n",
    "# Perform differencing twice\n",
    "difference = np.diff(array)\n",
    "difference_twice = np.diff(difference)\n",
    "\n",
    "print(difference_twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differenced Data: [-0.45613003  0.44363737 -0.08173323 ...  1.10271025  0.98600769\n",
      "  0.55796623]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def integrated_component(data, order):\n",
    "    \"\"\"\n",
    "    Perform differencing on the data.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy array): The input data array.\n",
    "    order (int): The order of differencing.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The differenced data.\n",
    "    \"\"\"\n",
    "    differenced_data = np.diff(data, n=order)\n",
    "    return differenced_data\n",
    "\n",
    "# Example\n",
    "data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "order = 1\n",
    "differenced_data = integrated_component(data, order)\n",
    "print(\"Differenced Data:\", differenced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Moving Average Component\n",
    "\n",
    "- **q**\n",
    "\n",
    "- This parameter represents the size of the moving average window.\n",
    "- It captures the relationship between an observation and a residual error from a moving average model applied to lagged observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50527,)\n",
      "(50527,)\n",
      "[5.59856424 5.18570755 5.70195313 ... 9.66550717 6.59087763 9.03954321]\n",
      "(50527,)\n"
     ]
    }
   ],
   "source": [
    "# MA (1) component logic\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Data from AR component\n",
    "actual = initial_data[2:]\n",
    "forecast = result_matrix\n",
    "\n",
    "print(actual.shape)\n",
    "print(forecast.shape)\n",
    "\n",
    "# Calculate forecast errors\n",
    "errors = actual - forecast\n",
    "\n",
    "# Create lagged errors and set the first lagged error to zero\n",
    "errors_lag1 = np.roll(errors, 1)\n",
    "errors_lag1[0] = 0\n",
    "\n",
    "# Parameters for MA(1) model\n",
    "theta = 0.3\n",
    "\n",
    "# Update forecasts\n",
    "updated_forecast = forecast + theta * errors_lag1 \n",
    "\n",
    "# Print the results\n",
    "print(updated_forecast)\n",
    "print(updated_forecast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 1 1]\n",
      "[0 0 2 2 1]\n",
      "Actual: [100 105 102 108 110]\n",
      "Forecast: [ 98 103 101 107 109]\n",
      "Updated Forecast: [ 98.  103.6 102.2 107.9 109.6]\n"
     ]
    }
   ],
   "source": [
    "# Basic example with sample data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "actual = np.array([100, 105, 102, 108, 110])\n",
    "forecast = np.array([98, 103, 101, 107, 109])\n",
    "\n",
    "# Calculate forecast errors\n",
    "errors = actual - forecast\n",
    "\n",
    "# Create lagged errors\n",
    "errors_lag1 = np.roll(errors, 1)\n",
    "errors_lag2 = np.roll(errors, 2)\n",
    "\n",
    "# Set the first two lagged errors to zero\n",
    "errors_lag1[:1] = 0\n",
    "errors_lag2[:2] = 0\n",
    "print(errors_lag1)\n",
    "print(errors_lag2)\n",
    "\n",
    "# MA(2) model \n",
    "theta_1 = 0.3\n",
    "theta_2 = 0.3\n",
    "\n",
    "# Update forecasts\n",
    "updated_forecast = forecast + theta_1 * errors_lag1 + theta_2 * errors_lag2\n",
    "\n",
    "# Print the results\n",
    "print(\"Actual:\", actual)\n",
    "print(\"Forecast:\", forecast)\n",
    "print(\"Updated Forecast:\", updated_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [100 105 102 108 110]\n",
      "Forecast: [ 98 103 101 107 109]\n",
      "Updated Forecast: [ 98.  103.6 102.2 107.9 109.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [5.65967417 5.57794094 5.60405207 ... 8.43535805 9.42136574 9.97933197]\n",
      "Forecast Data: [ 5.59856424  5.16737458  5.57878322 ... 11.06558672  7.37994624\n",
      "  8.42711736]\n",
      "Updated Forecast: [5.59856424 5.18570755 5.7202861  ... 9.41554264 5.19079809 8.25047461]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def moving_average_component_basic(actual, forecast, order, theta):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average (MA) component of an ARIMA model and update the forecast data.\n",
    "\n",
    "    Parameters:\n",
    "    actual (array-like): Array of actual data.\n",
    "    forecast (array-like): Array of forecast data.\n",
    "    order (int): Order of the MA model.\n",
    "    theta (array-like): Array of MA coefficients.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of updated forecast values.\n",
    "    \"\"\"\n",
    "    actual = np.array(actual)\n",
    "    forecast = np.array(forecast)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    # Ensure the lengths of actual and forecast are the same\n",
    "    min_length = min(len(actual), len(forecast))\n",
    "    actual = actual[:min_length]\n",
    "    forecast = forecast[:min_length]\n",
    "\n",
    "    # Calculate the errors\n",
    "    errors = actual - forecast\n",
    "    \n",
    "    # Initialize the updated forecast array as float64\n",
    "    updated_forecast = np.copy(forecast).astype(np.float64)\n",
    "    \n",
    "    # Create lagged errors and update the forecast\n",
    "    for i in range(1, order + 1):\n",
    "        lagged_errors = np.roll(errors, i)\n",
    "        lagged_errors[:i] = 0  # Set the first 'i' elements to zero\n",
    "        updated_forecast += theta[i - 1] * lagged_errors\n",
    "    \n",
    "    return updated_forecast\n",
    "\n",
    "# Example usage 1\n",
    "\n",
    "# Sample data\n",
    "actual = np.array([100, 105, 102, 108, 110])\n",
    "forecast = np.array([98, 103, 101, 107, 109])\n",
    "\n",
    "# MA(2) model parameters\n",
    "order = 2\n",
    "theta = [0.3, 0.3]\n",
    "\n",
    "# Update forecasts\n",
    "updated_forecast = moving_average_component_basic(actual, forecast, order, theta)\n",
    "\n",
    "# Print the results\n",
    "print(\"Actual:\", actual)\n",
    "print(\"Forecast:\", forecast)\n",
    "print(\"Updated Forecast:\", updated_forecast)\n",
    "\n",
    "\n",
    "# Example usage 2\n",
    "\n",
    "theta = [0.3, 0.3]\n",
    "order = 2\n",
    "initial_data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "original_data = initial_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component_basic(original_data, forecast_data, order, theta)\n",
    "print(\"Original Data:\", original_data)\n",
    "print(\"Forecast Data:\", forecast_data)\n",
    "print(\"Updated Forecast:\", updated_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [5.65967417 5.57794094 5.60405207 ... 8.43535805 9.42136574 9.97933197]\n",
      "Forecast Data: [ 5.59856424  5.16737458  5.57878322 ... 11.06558672  7.37994624\n",
      "  8.42711736]\n",
      "Updated Forecast: [5.59856424 5.18570755 5.7202861  ... 9.41554264 5.19079809 8.25047461]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def moving_average_component(original_data, forecast_data, order, theta):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average (MA) component of an ARIMA model and update the forecast data.\n",
    "\n",
    "    Parameters:\n",
    "    original_data (array-like): Array of original data.\n",
    "    forecast_data (array-like): Array of forecast data.\n",
    "    order (int): Order of the MA model.\n",
    "    theta (array-like): Array of MA coefficients.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of updated forecast values.\n",
    "    \"\"\"\n",
    "    original_data = np.array(original_data)\n",
    "    forecast_data = np.array(forecast_data)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    # Ensure the lengths of original_data and forecast_data are the same\n",
    "    min_length = min(len(original_data), len(forecast_data))\n",
    "    original_data = original_data[:min_length]\n",
    "    forecast_data = forecast_data[:min_length]\n",
    "\n",
    "    # Calculate the errors\n",
    "    errors = original_data - forecast_data\n",
    "    \n",
    "    # Create a matrix of lagged errors\n",
    "    lagged_errors = np.zeros((order, len(errors)))\n",
    "    # loop over MA order \n",
    "    for i in range(1, order + 1):\n",
    "        lagged_errors[i - 1, i:] = errors[:-i]\n",
    "    \n",
    "    # Calculate the weighted sum of lagged errors\n",
    "    weighted_lagged_errors = np.matmul(theta, lagged_errors)\n",
    "    \n",
    "    # Update the forecast\n",
    "    updated_forecast = forecast_data + weighted_lagged_errors\n",
    "    \n",
    "    return updated_forecast\n",
    "\n",
    "# Example usage\n",
    "theta = [0.3, 0.3]\n",
    "order = 2\n",
    "initial_data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "original_data = initial_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "print(\"Original Data:\", original_data)\n",
    "print(\"Forecast Data:\", forecast_data)\n",
    "print(\"Updated Forecast:\", updated_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [5.65967417 5.57794094 5.60405207 ... 8.43535805 9.42136574 9.97933197]\n",
      "Forecast Data: [ 5.59856424  5.16737458  5.57878322 ... 11.06558672  7.37994624\n",
      "  8.42711736]\n",
      "Updated Forecast: [5.59856424 5.18570755 5.7202861  ... 9.41554264 5.19079809 8.25047461]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def moving_average_component_v2(actual, forecast, order, theta):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average (MA) component of an ARIMA model and update the forecast data.\n",
    "\n",
    "    Parameters:\n",
    "    actual (array-like): Array of actual data.\n",
    "    forecast (array-like): Array of forecast data.\n",
    "    order (int): Order of the MA model.\n",
    "    theta (array-like): Array of MA coefficients.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of updated forecast values.\n",
    "    \"\"\"\n",
    "    actual = np.array(actual)\n",
    "    forecast = np.array(forecast)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    # Ensure the lengths of actual and forecast are the same\n",
    "    min_length = min(len(actual), len(forecast))\n",
    "    actual = actual[:min_length]\n",
    "    forecast = forecast[:min_length]\n",
    "\n",
    "    # Calculate the errors\n",
    "    errors = actual - forecast\n",
    "    \n",
    "    # Initialize the updated forecast array as float64\n",
    "    updated_forecast = np.copy(forecast).astype(np.float64)\n",
    "    \n",
    "    # Create lagged errors and update the forecast\n",
    "    for i in range(1, order + 1):\n",
    "        lagged_errors = np.roll(errors, i)\n",
    "        lagged_errors[:i] = 0  # Set the first 'i' elements to zero\n",
    "        updated_forecast += theta[i - 1] * lagged_errors\n",
    "    \n",
    "    return updated_forecast\n",
    "\n",
    "theta = [0.3, 0.3]\n",
    "order = 2\n",
    "initial_data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "original_data = initial_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component_v2(original_data, forecast_data, order, theta)\n",
    "print(\"Original Data:\", original_data)\n",
    "print(\"Forecast Data:\", forecast_data)\n",
    "print(\"Updated Forecast:\", updated_forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## ARIMA Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autoregressive models: AR(p)\n",
    "\n",
    "- mixed autoregressive moving average models: ARMA(p, q)\n",
    "\n",
    "- integration models: ARIMA(p, d, q)\n",
    "\n",
    "<br/>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #A - Dataset: wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset wind_speed\n",
      "### ARIMA (3,0,0) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "45,950.50\n"
     ]
    }
   ],
   "source": [
    "# AR\n",
    "# ARIMA (3,0,0)\n",
    "\n",
    "# read data\n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "lags = 2\n",
    "arima_vector = np.array([0.9208, -0.0111, 0.0766]) # Trained arima vector\n",
    "result_matrix = autoregressive_component(wind_speed, lags, arima_vector)\n",
    "\n",
    "error_metric = sum_of_squares_error(wind_speed[lags:], result_matrix)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset wind_speed\")\n",
    "print(\"### ARIMA (3,0,0) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset wind_speed\n",
      "### ARIMA (3,0,3) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "36,951.15\n"
     ]
    }
   ],
   "source": [
    "# AR + MA\n",
    "# ARIMA (3,0,3)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "arima_vector = np.array([-0.0723, -0.4126, -0.0111]) # Trained arima vector\n",
    "result_matrix = autoregressive_component(wind_speed, lags, arima_vector)\n",
    "\n",
    "# MA component\n",
    "theta = [0.6566, 0.9961, -0.6605]\n",
    "order = 3\n",
    "original_data = wind_speed[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "\n",
    "# Print results\n",
    "error_metric = sum_of_squares_error(wind_speed[lags+1:], updated_forecast)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset wind_speed\")\n",
    "print(\"### ARIMA (3,0,3) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset wind_speed\n",
      "### ARIMA (3,1,0) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "30,883.65\n"
     ]
    }
   ],
   "source": [
    "# AR + I \n",
    "# ARIMA (3,1,0)\n",
    "\n",
    "# read data\n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Differencing component\n",
    "diff_order = 1\n",
    "differenced_data = integrated_component(wind_speed, diff_order)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "arima_vector = np.array([-0.0766, -0.0864, -0.0465]) # Trained arima vector\n",
    "result_matrix = autoregressive_component(differenced_data, lags, arima_vector)\n",
    "\n",
    "error_metric = sum_of_squares_error(differenced_data[lags:], result_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset wind_speed\")\n",
    "print(\"### ARIMA (3,1,0) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset wind_speed\n",
      "### ARIMA (3,1,3) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "288,852.29\n"
     ]
    }
   ],
   "source": [
    "# AR + I + MA\n",
    "# ARIMA (3,1,3)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Differencing component\n",
    "diff_order = 1\n",
    "differenced_data = integrated_component(wind_speed, diff_order)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "arima_vector = np.array([0.6566, 0.9961, -0.6605]) # Trained arima vector\n",
    "result_matrix = autoregressive_component(differenced_data, lags, arima_vector)\n",
    "\n",
    "# MA component\n",
    "theta = [-0.7543, -0.9993, 0.7550]\n",
    "order = 3\n",
    "original_data = differenced_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "\n",
    "# Print results\n",
    "error_metric = sum_of_squares_error(differenced_data[lags+1:], updated_forecast)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset wind_speed\")\n",
    "print(\"### ARIMA (3,1,3) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #B- Dataset: energy_generation_solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset energy_generation_solar\n",
      "### ARIMA (3,0,0) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "65,336,245,585.35\n"
     ]
    }
   ],
   "source": [
    "# AR\n",
    "# ARIMA (3,0,0)\n",
    "\n",
    "# read data\n",
    "energy_generation_solar = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar_small.csv', delimiter=',', skip_header=1)\n",
    "lags = 1\n",
    "lagged_matrix = create_lagged_matrix(energy_generation_solar, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "error_metric = sum_of_squares_error(energy_generation_solar[lags:], result_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset energy_generation_solar\")\n",
    "print(\"### ARIMA (3,0,0) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset energy_generation_solar\n",
      "### ARIMA (3,1,0) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "22,305,125,234.48\n"
     ]
    }
   ],
   "source": [
    "# AR + I \n",
    "# ARIMA (3,1,0)\n",
    "\n",
    "# read data\n",
    "energy_generation_solar = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Differencing component\n",
    "diff_order = 2\n",
    "differenced_data = integrated_component(energy_generation_solar, diff_order)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(differenced_data, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411, 0.2856]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "error_metric = sum_of_squares_error(differenced_data[lags:], result_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset energy_generation_solar\")\n",
    "print(\"### ARIMA (3,1,0) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset energy_generation_solar\n",
      "### ARIMA (3,0,1) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "58,211,265,066.66\n"
     ]
    }
   ],
   "source": [
    "# AR + MA\n",
    "# ARIMA (3,0,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "energy_generation_solar = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(energy_generation_solar, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411, 0.2856]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "# MA component\n",
    "theta = [0.7, 0.7]\n",
    "order = 2\n",
    "original_data = energy_generation_solar[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "\n",
    "# Print results\n",
    "error_metric = sum_of_squares_error(energy_generation_solar[lags:], updated_forecast)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset energy_generation_solar\")\n",
    "print(\"### ARIMA (3,0,1) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset energy_generation_solar\n",
      "### ARIMA (3,1,1) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "40,886,542,809.99\n"
     ]
    }
   ],
   "source": [
    "# AR + I + MA\n",
    "# ARIMA (3,1,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "energy_generation_solar = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Differencing component\n",
    "diff_order = 1\n",
    "differenced_data = integrated_component(energy_generation_solar, diff_order)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(differenced_data, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411, 0.2856]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "# MA component\n",
    "theta = [0.7, 0.7]\n",
    "order = 2\n",
    "original_data = differenced_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "\n",
    "# Print results\n",
    "error_metric = sum_of_squares_error(differenced_data[lags:], updated_forecast)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset energy_generation_solar\")\n",
    "print(\"### ARIMA (3,1,1) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #C - Dataset: heart_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset heart_rate\n",
      "### ARIMA (3,0,0) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "966,415,324.07\n"
     ]
    }
   ],
   "source": [
    "# AR\n",
    "# ARIMA (3,0,0)\n",
    "\n",
    "# read data\n",
    "heart_rate = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate_small.csv', delimiter=',', skip_header=1)\n",
    "lags = 1\n",
    "lagged_matrix = create_lagged_matrix(heart_rate, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "error_metric = sum_of_squares_error(heart_rate[lags:], result_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset heart_rate\")\n",
    "print(\"### ARIMA (3,0,0) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset heart_rate\n",
      "### ARIMA (3,1,0) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "71,768,375.44\n"
     ]
    }
   ],
   "source": [
    "# AR + I \n",
    "# ARIMA (3,1,0)\n",
    "\n",
    "# read data\n",
    "heart_rate = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Differencing component\n",
    "diff_order = 2\n",
    "differenced_data = integrated_component(heart_rate, diff_order)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(differenced_data, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411, 0.2856]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "error_metric = sum_of_squares_error(differenced_data[lags:], result_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset heart_rate\")\n",
    "print(\"### ARIMA (3,1,0) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset heart_rate\n",
      "### ARIMA (3,0,1) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "43,788,195.14\n"
     ]
    }
   ],
   "source": [
    "# AR + MA\n",
    "# ARIMA (3,0,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "heart_rate = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(heart_rate, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411, 0.2856]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "# MA component\n",
    "theta = [0.7, 0.7]\n",
    "order = 2\n",
    "original_data = heart_rate[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "\n",
    "# Print results\n",
    "error_metric = sum_of_squares_error(heart_rate[lags:], updated_forecast)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset heart_rate\")\n",
    "print(\"### ARIMA (3,0,1) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset heart_rate\n",
      "### ARIMA (3,1,1) \n",
      "\n",
      "Error Metric: Sum of squares\n",
      "53,663,022.31\n"
     ]
    }
   ],
   "source": [
    "# AR + I + MA\n",
    "# ARIMA (3,1,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "heart_rate = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Differencing component\n",
    "diff_order = 1\n",
    "differenced_data = integrated_component(heart_rate, diff_order)\n",
    "\n",
    "# AR component\n",
    "lags = 2\n",
    "lagged_matrix = create_lagged_matrix(differenced_data, lags)\n",
    "\n",
    "arima_vector = np.array([1.9920, -1.3411, 0.2856]) # Trained arima vector\n",
    "result_matrix = matrix_vector_multiplication(lagged_matrix, arima_vector)\n",
    "\n",
    "# MA component\n",
    "theta = [0.3, 0.7]\n",
    "order = 2\n",
    "original_data = differenced_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component(original_data, forecast_data, order, theta)\n",
    "\n",
    "# Print results\n",
    "error_metric = sum_of_squares_error(differenced_data[lags:], updated_forecast)\n",
    "\n",
    "# Print the results\n",
    "print(\"### Dataset heart_rate\")\n",
    "print(\"### ARIMA (3,1,1) \\n\")\n",
    "print(\"Error Metric: Sum of squares\")\n",
    "print(f\"{error_metric:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Get ARIMA Parameter Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe wind_speed has 50529 rows.\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                50529\n",
      "Model:                 ARIMA(3, 0, 0)   Log Likelihood              -56809.358\n",
      "Date:                Mon, 26 Aug 2024   AIC                         113628.717\n",
      "Time:                        11:34:36   BIC                         113672.868\n",
      "Sample:                             0   HQIC                        113642.540\n",
      "                              - 50529                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          7.5580      0.253     29.868      0.000       7.062       8.054\n",
      "ar.L1          0.9208      0.002    574.498      0.000       0.918       0.924\n",
      "ar.L2         -0.0111      0.003     -3.374      0.001      -0.018      -0.005\n",
      "ar.L3          0.0766      0.003     24.792      0.000       0.071       0.083\n",
      "sigma2         0.5547      0.001    481.093      0.000       0.552       0.557\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.49   Jarque-Bera (JB):           1200723.24\n",
      "Prob(Q):                              0.48   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.83   Skew:                            -0.00\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        26.88\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# Dataset wind_speed\n",
    " \n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Get the data in an numpy array \n",
    "wind_speed = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "print(f\"Dataframe wind_speed has {wind_speed.size} rows.\")\n",
    "\n",
    "# Fit ARIMA model with only AR component (p=3, d=0, q=0)\n",
    "model = ARIMA(wind_speed, order=(3, 0, 0))\n",
    "arima_model = model.fit()\n",
    "\n",
    "print(arima_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe wind_speed has 35045 rows.\n",
    "\n",
    "                               SARIMAX Results                                \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   No. Observations:                35045\n",
    "Model:                 ARIMA(3, 0, 0)   Log Likelihood             -245602.035\n",
    "Date:                Fri, 23 Aug 2024   AIC                         491214.070\n",
    "Time:                        00:51:56   BIC                         491256.392\n",
    "Sample:                             0   HQIC                        491227.550\n",
    "                              - 35045                                         \n",
    "Covariance Type:                  opg                                         \n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const       1432.7054     25.785     55.564      0.000    1382.168    1483.243\n",
    "ar.L1          1.9920      0.002    878.019      0.000       1.988       1.996\n",
    "ar.L2         -1.3411      0.003   -394.514      0.000      -1.348      -1.334\n",
    "ar.L3          0.2856      0.002    127.535      0.000       0.281       0.290\n",
    "sigma2      7.157e+04    202.462    353.494      0.000    7.12e+04     7.2e+04\n",
    "===================================================================================\n",
    "Ljung-Box (L1) (Q):                 134.53   Jarque-Bera (JB):           3117759.51\n",
    "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
    "Heteroskedasticity (H):               1.14   Skew:                             1.55\n",
    "Prob(H) (two-sided):                  0.00   Kurtosis:                        49.10\n",
    "===================================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe energy_generation_solar has 35045 rows.\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                35045\n",
      "Model:                 ARIMA(3, 0, 0)   Log Likelihood             -245602.035\n",
      "Date:                Mon, 26 Aug 2024   AIC                         491214.070\n",
      "Time:                        11:35:04   BIC                         491256.392\n",
      "Sample:                             0   HQIC                        491227.550\n",
      "                              - 35045                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1432.7054     25.785     55.564      0.000    1382.168    1483.243\n",
      "ar.L1          1.9920      0.002    878.019      0.000       1.988       1.996\n",
      "ar.L2         -1.3411      0.003   -394.514      0.000      -1.348      -1.334\n",
      "ar.L3          0.2856      0.002    127.535      0.000       0.281       0.290\n",
      "sigma2      7.157e+04    202.462    353.494      0.000    7.12e+04     7.2e+04\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                 134.53   Jarque-Bera (JB):           3117759.51\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.14   Skew:                             1.55\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        49.10\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# Dataset energy_generation_solar\n",
    " \n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Get the data in an numpy array \n",
    "energy_generation_solar = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "print(f\"Dataframe energy_generation_solar has {energy_generation_solar.size} rows.\")\n",
    "\n",
    "# Fit ARIMA model with only AR component (p=3, d=0, q=0)\n",
    "model = ARIMA(energy_generation_solar, order=(3, 0, 0))\n",
    "arima_model = model.fit()\n",
    "\n",
    "print(arima_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe energy_generation_solar has 35045 rows.\n",
    "\n",
    "                               SARIMAX Results                                \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   No. Observations:                35045\n",
    "Model:                 ARIMA(3, 0, 0)   Log Likelihood             -245602.035\n",
    "Date:                Fri, 23 Aug 2024   AIC                         491214.070\n",
    "Time:                        00:52:46   BIC                         491256.392\n",
    "Sample:                             0   HQIC                        491227.550\n",
    "                              - 35045                                         \n",
    "Covariance Type:                  opg                                         \n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const       1432.7054     25.785     55.564      0.000    1382.168    1483.243\n",
    "ar.L1          1.9920      0.002    878.019      0.000       1.988       1.996\n",
    "ar.L2         -1.3411      0.003   -394.514      0.000      -1.348      -1.334\n",
    "ar.L3          0.2856      0.002    127.535      0.000       0.281       0.290\n",
    "sigma2      7.157e+04    202.462    353.494      0.000    7.12e+04     7.2e+04\n",
    "===================================================================================\n",
    "Ljung-Box (L1) (Q):                 134.53   Jarque-Bera (JB):           3117759.51\n",
    "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
    "Heteroskedasticity (H):               1.14   Skew:                             1.55\n",
    "Prob(H) (two-sided):                  0.00   Kurtosis:                        49.10\n",
    "===================================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe heart_rate has 1154680 rows.\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:              1154680\n",
      "Model:                 ARIMA(3, 0, 0)   Log Likelihood            -2444762.852\n",
      "Date:                Mon, 26 Aug 2024   AIC                        4889535.704\n",
      "Time:                        11:35:48   BIC                        4889595.501\n",
      "Sample:                             0   HQIC                       4889552.066\n",
      "                            - 1154680                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         79.7569      0.312    255.567      0.000      79.145      80.369\n",
      "ar.L1          1.0247      0.000   3374.100      0.000       1.024       1.025\n",
      "ar.L2          0.0151      0.000     52.620      0.000       0.015       0.016\n",
      "ar.L3         -0.0461      0.000   -171.161      0.000      -0.047      -0.046\n",
      "sigma2         4.0416      0.001   4087.531      0.000       4.040       4.044\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   3.74   Jarque-Bera (JB):         338317482.96\n",
      "Prob(Q):                              0.05   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.40   Skew:                            -0.58\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        86.85\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# Dataset heart_rate\n",
    " \n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Get the data in an numpy array \n",
    "heart_rate = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "print(f\"Dataframe heart_rate has {heart_rate.size} rows.\")\n",
    "\n",
    "# Fit ARIMA model with only AR component (p=3, d=0, q=0)\n",
    "model = ARIMA(heart_rate, order=(3, 0, 0))\n",
    "arima_model = model.fit()\n",
    "\n",
    "print(arima_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [5.2160368  5.65967417 5.57794094 ... 8.43535805 9.42136574 9.97933197]\n",
      "Forecast Data: [ 7.849   1.5874  3.4997 ...  1.0079 -2.7702 -8.2143]\n",
      "Updated Forecast: [ 7.849       2.80908225  4.12317228 ...  4.23573741 -3.60666028\n",
      "  3.27701959]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def moving_average_component_v1(original_data, forecast_data, order, theta):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average (MA) component of an ARIMA model and update the forecast data.\n",
    "\n",
    "    Parameters:\n",
    "    original_data (array-like): Array of original data.\n",
    "    forecast_data (array-like): Array of forecast data.\n",
    "    order (int): Order of the MA model.\n",
    "    theta (array-like): Array of MA coefficients.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of updated forecast values.\n",
    "    \"\"\"\n",
    "    original_data = np.array(original_data)\n",
    "    forecast_data = np.array(forecast_data)\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    # Ensure the lengths of original_data and forecast_data are the same\n",
    "    min_length = min(len(original_data), len(forecast_data))\n",
    "    original_data = original_data[:min_length]\n",
    "    forecast_data = forecast_data[:min_length]\n",
    "\n",
    "    # Calculate the errors\n",
    "    errors = original_data - forecast_data   \n",
    "    # Create a matrix where each row is a shifted version of the errors array\n",
    "    shifted_errors = np.array([np.roll(errors, i) for i in range(order)]).T\n",
    "    # Set the first 'order' rows to zero to handle the initial condition\n",
    "    shifted_errors[:order, :] = 0\n",
    "    \n",
    "    # Calculate the updated forecast\n",
    "    updated_forecast = np.copy(forecast_data)\n",
    "    updated_forecast[order:] += np.dot(shifted_errors[order:], theta)\n",
    "\n",
    "    return updated_forecast\n",
    "\n",
    "# Example usage\n",
    "\n",
    "theta = [0.3]\n",
    "order = 1\n",
    "initial_data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed_small.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "original_data = initial_data[order:]\n",
    "forecast_data = result_matrix\n",
    "\n",
    "updated_forecast = moving_average_component_v1(original_data, forecast_data, order, theta)\n",
    "print(\"Original Data:\", original_data)\n",
    "print(\"Forecast Data:\", forecast_data)\n",
    "print(\"Updated Forecast:\", updated_forecast)\n",
    "\n",
    "# wrong output!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
