{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Smoothing: SystemDS\n",
    "\n",
    "Notes & Scripts\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export JAVA_HOME=`/usr/libexec/java_home -v 11`\n",
    "java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export SPARK_HOME=\"/opt/homebrew/opt/spark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-exec option, must be one of [hadoop, singlenode, hybrid, HYBRID, spark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "## Dataset: wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe wind_speed has 25265000 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Get the data in a numpy array\n",
    "data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/wind_turbine_scada.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Slice the data to only get the wind speed column\n",
    "wind_speed = data[:, 2]\n",
    "wind_speed = wind_speed[~np.isnan(wind_speed)]\n",
    "\n",
    "# Replication factor\n",
    "factor = 500\n",
    "base_wind_speed = wind_speed\n",
    "\n",
    "# Concatenate the wind_speed array 'factor' times\n",
    "for i in range(factor - 1):\n",
    "    wind_speed = np.concatenate((wind_speed, base_wind_speed))\n",
    "\n",
    "# Save the wind_speed array to a CSV file\n",
    "np.savetxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed.csv', wind_speed, delimiter=',')\n",
    "\n",
    "print(f\"Saved dataframe wind_speed has {wind_speed.size} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "wind_speed = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed.csv\", format=\"csv\", header=TRUE, sep=\",\")\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe wind_speed has \" + toString(nrow(wind_speed)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Start timing\n",
    "start_time = time()\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 2:nrow(wind_speed)) {\n",
    "  smoothed_value = alpha * wind_speed[i] + (1 - alpha) * smoothed_value\n",
    "}\n",
    "\n",
    "# End timing and calculate execution time\n",
    "end_time = time()\n",
    "function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset wind_speed')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "wind_speed = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=25264999, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe wind_speed has \" + toString(nrow(wind_speed)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Vector to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = numeric(number_of_executions)\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 1:number_of_executions) {\n",
    "    start_time <- time()\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for (i in 2:nrow(wind_speed)) {\n",
    "    smoothed_value = alpha * wind_speed[i] + (1 - alpha) * smoothed_value\n",
    "    }\n",
    "\n",
    "    # End timing and calculate execution time\n",
    "    end_time = time()\n",
    "    function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time <- Sys.time()\n",
    "    execution_times[i] <- as.numeric(difftime(end_time, start_time, units = \"secs\"))\n",
    "}\n",
    "\n",
    "# Calculate the function time\n",
    "function_time <- median(execution_times)\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset wind_speed')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/wind_speed/windspeed_experiment3.dml -exec singlenode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "Dataframe wind_speed has 25264999 rows.\n",
    "1133.814014792\n",
    "1133.425738708\n",
    "### Dataset wind_speed\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 1133.61987675 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe wind_speed has 25264999 rows.\n",
    "\n",
    "### Dataset wind_speed\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 1113.519333333 seconds     # 18 minutes\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t1127,025 sec.\n",
    "Total compilation time:\t\t0,315 sec.\n",
    "Total execution time:\t\t1126,710 sec.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t101059994/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t0/0/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t16,096/1,618/3,913/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/25264999.\n",
    "HOP DAGs recompile time:\t1010,638 sec.\n",
    "Total JIT compile time:\t\t6.899 sec.\n",
    "Total JVM GC count:\t\t267.\n",
    "Total JVM GC time:\t\t1.573 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)     Count\n",
    "  1  createvar     25,641  75794996\n",
    "  2  +*            24,696  25264998\n",
    "  3  rightIndex    17,697  25264999\n",
    "  4  nrow          13,110         2\n",
    "  5  *             12,769  25264998\n",
    "  6  rmvar          7,397  50530010\n",
    "  7  mvvar          4,962  25265003\n",
    "  8  toString       0,068         1\n",
    "  9  -              0,007         2\n",
    " 10  +              0,004         7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "wind_speed = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed.csv\", format=\"csv\", header=TRUE, sep=\",\")\n",
    "\n",
    "# Extract the wind speed column\n",
    "wind_speed = data\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe wind_speed has \" + toString(nrow(wind_speed)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Start timing\n",
    "start_time = time()\n",
    "\n",
    "# Vectorized exponential smoothing\n",
    "n = nrow(wind_speed)\n",
    "weights = rev(alpha * (1 - alpha) ^ seq(0, n-1, 1))\n",
    "smoothed = rev(cumsum(weights * wind_speed))\n",
    "smoothed_value = smoothed[1] / sum(weights)\n",
    "\n",
    "# End timing and calculate execution time\n",
    "end_time = time()\n",
    "function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset wind_speed')\n",
    "print('### #2 Vectorized \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "wind_speed = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/wind_speed.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=25264999, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe wind_speed has \" + toString(nrow(wind_speed)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Vector to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = matrix(0, number_of_executions, 1)\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = wind_speed[1]\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 1:number_of_executions) {\n",
    "    start_time = time()\n",
    "\n",
    "    # Vectorized exponential smoothing\n",
    "    n = nrow(wind_speed)\n",
    "    weights = rev(alpha * (1 - alpha) ^ seq(0, n-1, 1))\n",
    "    smoothed = rev(cumsum(weights * wind_speed))\n",
    "    smoothed_value = smoothed[1] / sum(weights)\n",
    "\n",
    "    # End timing and calculate execution time\n",
    "    end_time = time()\n",
    "    function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "    print(function_time)\n",
    "    execution_times[i, 1] = function_time\n",
    "}\n",
    "\n",
    "# Calculate the function time\n",
    "function_time <- avg(execution_times)\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset wind_speed')\n",
    "print('### #2 Vectorized \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/wind_speed/windspeed_experiment4.dml -exec singlenode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe wind_speed has 25264999 rows.\n",
    "3.93455125\n",
    "3.384092208\n",
    "3.316342208\n",
    "3.485522208\n",
    "3.425112125\n",
    "3.322466666\n",
    "3.326216833\n",
    "3.384802458\n",
    "3.427035\n",
    "3.327018541\n",
    "\n",
    "### Dataset wind_speed\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 3.4333159497 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe wind_speed has 25264999 rows.\n",
    "\n",
    "### Dataset wind_speed\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 3.79856075 seconds\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t13,974 sec.\n",
    "Total compilation time:\t\t0,266 sec.\n",
    "Total execution time:\t\t13,709 sec.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t11/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t1/6/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t9,898/0,000/0,002/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/2.\n",
    "HOP DAGs recompile time:\t0,009 sec.\n",
    "Total JIT compile time:\t\t1.706 sec.\n",
    "Total JVM GC count:\t\t21.\n",
    "Total JVM GC time:\t\t0.159 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)  Count\n",
    "  1  nrow           9,902      1\n",
    "  2  ^              2,830      1\n",
    "  3  *              0,421      2\n",
    "  4  ucumk+         0,184      1\n",
    "  5  seq            0,133      1\n",
    "  6  rev            0,118      2\n",
    "  7  uak+           0,099      1\n",
    "  8  -              0,007      3\n",
    "  9  toString       0,004      1\n",
    " 10  rmvar          0,003     22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/wind_speed/windspeed_experiment3.dml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe wind_speed has 25264999 rows.\n",
    "\n",
    "51.312511375\n",
    "53.538804916\n",
    "\n",
    "### Dataset wind_speed\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 52.425658145499995 seconds\n",
    "SystemDS Statistics:\n",
    "Total execution time:           117,079 sec.\n",
    "Number of executed Spark inst:  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe wind_speed has 25264999 rows.\n",
    "\n",
    "### Dataset wind_speed\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 1130.060546416 seconds     # 19 minutes\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t1139,188 sec.\n",
    "Total compilation time:\t\t0,408 sec.\n",
    "Total execution time:\t\t1138,779 sec.\n",
    "Number of compiled Spark inst:\t8.\n",
    "Number of executed Spark inst:\t0.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t101059994/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t0/1/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t12,929/2,179/5,395/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t1/25265002.\n",
    "HOP DAGs recompile time:\t1024,849 sec.\n",
    "Spark ctx create time (lazy):\t0,000 sec.\n",
    "Spark trans counts (par,bc,col):0/0/0.\n",
    "Spark trans times (par,bc,col):\t0,000/0,000/0,000 secs.\n",
    "Total JIT compile time:\t\t6.586 sec.\n",
    "Total JVM GC count:\t\t278.\n",
    "Total JVM GC time:\t\t1.4 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)     Count\n",
    "  1  createvar     25,370  75794998\n",
    "  2  +*            25,244  25264998\n",
    "  3  rightIndex    18,479  25264999\n",
    "  4  *             12,859  25264998\n",
    "  5  sp_csvrblk     8,638         1\n",
    "  6  rmvar          7,475  50530002\n",
    "  7  mvvar          6,140  25265011\n",
    "  8  toString       0,015         1\n",
    "  9  -              0,008         2\n",
    " 10  time           0,002         2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/wind_speed/windspeed_experiment4.dml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe wind_speed has 25264999 rows.\n",
    "3.7066065\n",
    "3.390889375\n",
    "3.371399875\n",
    "3.28144475\n",
    "3.326555458\n",
    "3.301074333\n",
    "3.314003417\n",
    "3.406505208\n",
    "3.304629166\n",
    "3.314920708\n",
    "### Dataset wind_speed\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 3.371802879 seconds\n",
    "SystemDS Statistics:\n",
    "Total execution time:           46,782 sec.\n",
    "Number of executed Spark inst:  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe wind_speed has 25264999 rows.\n",
    "\n",
    "### Dataset wind_speed\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,729\n",
    "\n",
    "The function was executed in 3.914272 seconds\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t18,274 sec.\n",
    "Total compilation time:\t\t1,292 sec.\n",
    "Total execution time:\t\t16,983 sec.\n",
    "Number of compiled Spark inst:\t12.\n",
    "Number of executed Spark inst:\t0.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t11/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t1/7/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t13,050/0,000/0,003/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/3.\n",
    "HOP DAGs recompile time:\t0,011 sec.\n",
    "Spark ctx create time (lazy):\t0,577 sec.\n",
    "Spark trans counts (par,bc,col):0/0/0.\n",
    "Spark trans times (par,bc,col):\t0,000/0,000/0,000 secs.\n",
    "Total JIT compile time:\t\t3.915 sec.\n",
    "Total JVM GC count:\t\t14.\n",
    "Total JVM GC time:\t\t0.262 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)  Count\n",
    "  1  sp_csvrblk    13,056      1\n",
    "  2  ^              2,813      1\n",
    "  3  *              0,509      2\n",
    "  4  ucumk+         0,197      1\n",
    "  5  rev            0,140      2\n",
    "  6  seq            0,140      1\n",
    "  7  uak+           0,108      1\n",
    "  8  -              0,007      3\n",
    "  9  toString       0,004      1\n",
    " 10  rmvar          0,001     19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: energy_generation_solar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe energy_dataset has 49064400 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Get the data in a numpy array\n",
    "data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/energy_dataset.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Slice the data to only get the energy_dataset column\n",
    "energy_dataset = data[:, 18]\n",
    "energy_dataset = energy_dataset[~np.isnan(energy_dataset)]\n",
    "\n",
    "# Replication factor\n",
    "factor = 1400\n",
    "base_energy_dataset = energy_dataset\n",
    "\n",
    "# Concatenate the wind_speed array 'factor' times\n",
    "for i in range(factor - 1):\n",
    "    energy_dataset = np.concatenate((energy_dataset, base_energy_dataset))\n",
    "\n",
    "# Save the wind_speed array to a CSV file\n",
    "np.savetxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar.csv', energy_dataset, delimiter=',')\n",
    "\n",
    "print(f\"Saved dataframe energy_dataset has {energy_dataset.size} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "energy_generation_solar = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar.csv\", format=\"csv\", header=TRUE, sep=\",\")\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe energy_generation_solar has \" + toString(nrow(energy_generation_solar)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = energy_generation_solar[1]\n",
    "\n",
    "# Start timing\n",
    "start_time = time()\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 2:nrow(energy_generation_solar)) {\n",
    "  smoothed_value = alpha * energy_generation_solar[i] + (1 - alpha) * smoothed_value\n",
    "}\n",
    "\n",
    "# End timing and calculate execution time\n",
    "end_time = time()\n",
    "function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset energy_generation_solar')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for energy_generation_solar is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "energy_generation_solar = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=49064400, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe energy_generation_solar has \" + toString(nrow(energy_generation_solar)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = energy_generation_solar[1]\n",
    "\n",
    "# Vector to store execution times\n",
    "number_of_executions = 2\n",
    "execution_times = matrix(0, number_of_executions, 1)\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 1:number_of_executions) {\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for (j in 2:nrow(energy_generation_solar)) {\n",
    "        smoothed_value = alpha * energy_generation_solar[j] + (1 - alpha) * smoothed_value\n",
    "    }\n",
    "\n",
    "    # End timing and calculate execution time\n",
    "    end_time = time()\n",
    "    function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "    print(function_time)\n",
    "    execution_times[i, 1] = function_time\n",
    "}\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = avg(execution_times)\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset energy_generation_solar')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/energy_generation/energy_experiment3.dml -exec singlenode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe energy_generation_solar has 49064399 rows.\n",
    "\n",
    "2221.434682917\n",
    "2227.429070292\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 33,090\n",
    "\n",
    "The function was executed in 2224.4318766045 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe energy_generation_solar has 49064399 rows.\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for energy_generation_solar is: 33,090\n",
    "\n",
    "The function was executed in 2156.596293625 seconds   # 36 minutes\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t2173,938 sec.\n",
    "Total compilation time:\t\t0,289 sec.\n",
    "Total execution time:\t\t2173,649 sec.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t196257594/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t0/0/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t24,023/4,192/8,546/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/49064399.\n",
    "HOP DAGs recompile time:\t1957,299 sec.\n",
    "Total JIT compile time:\t\t6.965 sec.\n",
    "Total JVM GC count:\t\t525.\n",
    "Total JVM GC time:\t\t2.426 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)      Count\n",
    "  1  +*            47,093   49064398\n",
    "  2  createvar     46,813  147193196\n",
    "  3  rightIndex    32,321   49064399\n",
    "  4  *             23,832   49064398\n",
    "  5  rmvar         20,621   98128810\n",
    "  6  nrow          17,018          2\n",
    "  7  mvvar          9,298   49064403\n",
    "  8  toString       0,023          1\n",
    "  9  -              0,007          2\n",
    " 10  +              0,004          7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "energy_generation_solar = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar.csv\", format=\"csv\", header=TRUE, sep=\",\")\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe energy_generation_solar has \" + toString(nrow(energy_generation_solar)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = energy_generation_solar[1]\n",
    "\n",
    "# Start timing\n",
    "start_time = time()\n",
    "\n",
    "# Vectorized exponential smoothing\n",
    "n = nrow(energy_generation_solar)\n",
    "weights = rev(alpha * (1 - alpha) ^ seq(0, n-1, 1))\n",
    "smoothed = rev(cumsum(weights * energy_generation_solar))\n",
    "smoothed_value = smoothed[1] / sum(weights)\n",
    "\n",
    "# End timing and calculate execution time\n",
    "end_time = time()\n",
    "function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset energy_generation_solar')\n",
    "print('### #2 Vectorized \\n')\n",
    "print('The last smoothed value for energy_generation_solar is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "energy_generation_solar = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/energy_generation_solar.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=49064400, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe energy_generation_solar has \" + toString(nrow(energy_generation_solar)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = energy_generation_solar[1]\n",
    "\n",
    "# Vector to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = matrix(0, number_of_executions, 1)\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 1:number_of_executions) {\n",
    "    start_time = time()\n",
    "\n",
    "    # Vectorized exponential smoothing\n",
    "    n = nrow(energy_generation_solar)\n",
    "    weights = rev(alpha * (1 - alpha) ^ seq(0, n-1, 1))\n",
    "    smoothed = rev(cumsum(weights * energy_generation_solar))\n",
    "    smoothed_value = smoothed[1] / sum(weights)\n",
    "\n",
    "    # End timing and calculate execution time\n",
    "    end_time = time()\n",
    "    function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "    print(function_time)\n",
    "    execution_times[i, 1] = function_time\n",
    "}\n",
    "\n",
    "# Calculate the function time\n",
    "function_time <- avg(execution_times)\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset energy_generation_solar')\n",
    "print('### #2 Vectorized \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/energy_generation/energy_experiment4.dml -exec singlenode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe energy_generation_solar has 49064399 rows.\n",
    "\n",
    "8.881965375\n",
    "7.247304834\n",
    "7.131209625\n",
    "6.9798055\n",
    "6.872244708\n",
    "7.195350875\n",
    "7.021430667\n",
    "6.968126208\n",
    "7.003603083\n",
    "7.237802125\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 33,090\n",
    "\n",
    "The function was executed in 7.2538843 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe energy_generation_solar has 49064399 rows.\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for energy_generation_solar is: 33,090\n",
    "\n",
    "The function was executed in 7.740103042 seconds\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t32,441 sec.\n",
    "Total compilation time:\t\t0,299 sec.\n",
    "Total execution time:\t\t32,142 sec.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t11/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t1/6/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t24,376/0,000/0,007/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/2.\n",
    "HOP DAGs recompile time:\t0,037 sec.\n",
    "Total JIT compile time:\t\t3.079 sec.\n",
    "Total JVM GC count:\t\t20.\n",
    "Total JVM GC time:\t\t0.247 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)  Count\n",
    "  1  nrow          24,380      1\n",
    "  2  ^              5,589      1\n",
    "  3  ucumk+         0,645      1\n",
    "  4  *              0,524      2\n",
    "  5  rev            0,413      2\n",
    "  6  uak+           0,306      1\n",
    "  7  seq            0,219      1\n",
    "  8  +              0,014      7\n",
    "  9  -              0,008      3\n",
    " 10  rightIndex     0,004      1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/energy_generation/energy_experiment3.dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe energy_generation_solar has 49064400 rows.\n",
    "\n",
    "102.580072542\n",
    "112.456740583\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for energy_generation_solar is: 9,927\n",
    "\n",
    "The function was executed in 107.51840656249999 seconds\n",
    "SystemDS Statistics:\n",
    "Total execution time:           236,813 sec.\n",
    "Number of executed Spark inst:  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe energy_generation_solar has 49064399 rows.\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for energy_generation_solar is: 33,090\n",
    "\n",
    "The function was executed in 2265.317802125 seconds   # 38 minutes\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t2287,721 sec.\n",
    "Total compilation time:\t\t0,451 sec.\n",
    "Total execution time:\t\t2287,270 sec.\n",
    "Number of compiled Spark inst:\t8.\n",
    "Number of executed Spark inst:\t0.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t196257594/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t0/1/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t29,322/4,627/9,539/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t1/49064402.\n",
    "HOP DAGs recompile time:\t2063,036 sec.\n",
    "Spark ctx create time (lazy):\t0,000 sec.\n",
    "Spark trans counts (par,bc,col):0/0/0.\n",
    "Spark trans times (par,bc,col):\t0,000/0,000/0,000 secs.\n",
    "Total JIT compile time:\t\t8.472 sec.\n",
    "Total JVM GC count:\t\t516.\n",
    "Total JVM GC time:\t\t2.596 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)      Count\n",
    "  1  +*            49,741   49064398\n",
    "  2  createvar     48,842  147193198\n",
    "  3  rightIndex    36,587   49064399\n",
    "  4  *             25,001   49064398\n",
    "  5  sp_csvrblk    21,863          1\n",
    "  6  rmvar         13,095   98128802\n",
    "  7  mvvar          7,665   49064411\n",
    "  8  toString       0,018          1\n",
    "  9  -              0,009          2\n",
    " 10  time           0,002          2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/energy_generation/energy_experiment4.dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe energy_generation_solar has 49064400 rows.\n",
    "8.415589958\n",
    "6.630199458\n",
    "6.666481542\n",
    "6.907580833\n",
    "6.992634542\n",
    "6.743489\n",
    "6.789508666\n",
    "6.863836583\n",
    "6.690859\n",
    "6.607737917\n",
    "### Dataset energy_generation_solar\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 9,927\n",
    "\n",
    "The function was executed in 6.9307917499 seconds\n",
    "SystemDS Statistics:\n",
    "Total execution time:           89,965 sec.\n",
    "Number of executed Spark inst:  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe energy_generation_solar has 49064399 rows.\n",
    "\n",
    "### Dataset energy_generation_solar\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for energy_generation_solar is: 33,090\n",
    "\n",
    "The function was executed in 8.207912375 seconds\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t29,302 sec.\n",
    "Total compilation time:\t\t1,221 sec.\n",
    "Total execution time:\t\t28,081 sec.\n",
    "Number of compiled Spark inst:\t12.\n",
    "Number of executed Spark inst:\t0.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t11/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t1/7/1/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t19,843/0,000/0,740/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/3.\n",
    "HOP DAGs recompile time:\t0,025 sec.\n",
    "Spark ctx create time (lazy):\t0,578 sec.\n",
    "Spark trans counts (par,bc,col):0/0/0.\n",
    "Spark trans times (par,bc,col):\t0,000/0,000/0,000 secs.\n",
    "Total JIT compile time:\t\t3.334 sec.\n",
    "Total JVM GC count:\t\t21.\n",
    "Total JVM GC time:\t\t0.291 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)  Count\n",
    "  1  sp_csvrblk    19,851      1\n",
    "  2  ^              5,707      1\n",
    "  3  ucumk+         1,055      1\n",
    "  4  *              0,595      2\n",
    "  5  uak+           0,291      1\n",
    "  6  rev            0,285      2\n",
    "  7  seq            0,253      1\n",
    "  8  -              0,006      3\n",
    "  9  rmvar          0,005     18\n",
    " 10  toString       0,004      1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: heart_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe heart_rate has 103921290 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Get the data in a numpy array\n",
    "data = np.genfromtxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/heartrate_seconds_merged.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Slice the data to only get the energy_dataset column\n",
    "heart_rate = data[:, 2]\n",
    "heart_rate = heart_rate[~np.isnan(heart_rate)]\n",
    "\n",
    "# Replication factor\n",
    "factor = 90\n",
    "base_heart_rate = heart_rate\n",
    "\n",
    "# Concatenate the wind_speed array 'factor' times\n",
    "for i in range(factor - 1):\n",
    "    heart_rate = np.concatenate((heart_rate, base_heart_rate))\n",
    "\n",
    "# Save the wind_speed array to a CSV file\n",
    "np.savetxt('/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate.csv', heart_rate, delimiter=',')\n",
    "\n",
    "print(f\"Saved dataframe heart_rate has {heart_rate.size} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Run\n",
    "\n",
    "# Read the CSV file into a frame\n",
    "heart_rate = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=103921290, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe heart_rate has \" + toString(nrow(heart_rate)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = heart_rate[1]\n",
    "\n",
    "# Start timing\n",
    "start_time = time()\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 2:nrow(heart_rate)) {\n",
    "  smoothed_value = alpha * heart_rate[i] + (1 - alpha) * smoothed_value\n",
    "}\n",
    "\n",
    "# End timing and calculate execution time\n",
    "end_time = time()\n",
    "function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset heart_rate')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for heart_rate is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Runs\n",
    "\n",
    "# Read the CSV file into a frame\n",
    "heart_rate = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=103921290, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe heart_rate has \" + toString(nrow(heart_rate)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = heart_rate[1]\n",
    "\n",
    "# Vector to store execution times\n",
    "number_of_executions = 2\n",
    "execution_times = matrix(0, number_of_executions, 1)\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 1:number_of_executions) {\n",
    "    start_time = time()\n",
    "\n",
    "    # Perform exponential smoothing on the data\n",
    "    for (j in 2:nrow(heart_rate)) {\n",
    "        smoothed_value = alpha * heart_rate[j] + (1 - alpha) * smoothed_value\n",
    "    }\n",
    "\n",
    "    # End timing and calculate execution time\n",
    "    end_time = time()\n",
    "    function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "    print(function_time)\n",
    "    execution_times[i, 1] = function_time\n",
    "}\n",
    "\n",
    "# Calculate the function time\n",
    "function_time = avg(execution_times)\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset heart_rate')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/heart_rate/hr_experiment3.dml -exec singlenode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "4595.563075042\n",
    "4572.6757565\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 98,778\n",
    "\n",
    "The function was executed in 4584.119415771 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for heart_rate is: 98,778\n",
    "\n",
    "The function was executed in 4582.313366125 seconds     # 76 minutes\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t4630,489 sec.\n",
    "Total compilation time:\t\t0,337 sec.\n",
    "Total execution time:\t\t4630,152 sec.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t415685154/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t0/0/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t62,608/6,769/16,628/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/103921289.\n",
    "HOP DAGs recompile time:\t4163,696 sec.\n",
    "Total JIT compile time:\t\t7.297 sec.\n",
    "Total JVM GC count:\t\t1082.\n",
    "Total JVM GC time:\t\t5.337 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)      Count\n",
    "  1  createvar    108,146  311763866\n",
    "  2  +*            97,272  103921288\n",
    "  3  rightIndex    68,063  103921289\n",
    "  4  *             48,838  103921288\n",
    "  5  nrow          47,757          2\n",
    "  6  rmvar         36,506  207842590\n",
    "  7  mvvar         21,832  103921293\n",
    "  8  toString       0,047          1\n",
    "  9  +              0,018          7\n",
    " 10  -              0,008          2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "heart_rate = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=103921290, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe heart_rate has \" + toString(nrow(heart_rate)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = heart_rate[1]\n",
    "\n",
    "# Start timing\n",
    "start_time = time()\n",
    "\n",
    "# Vectorized exponential smoothing\n",
    "n = nrow(heart_rate)\n",
    "weights = rev(alpha * (1 - alpha) ^ seq(0, n-1, 1))\n",
    "smoothed = rev(cumsum(weights * heart_rate))\n",
    "smoothed_value = smoothed[1] / sum(weights)\n",
    "\n",
    "# End timing and calculate execution time\n",
    "end_time = time()\n",
    "function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset heart_rate')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for heart_rate is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a frame\n",
    "heart_rate = read(\"/Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/data_files/prepocessed_datafiles/heart_rate.csv\", format=\"csv\", header=TRUE, sep=\",\", rows=103921290, cols=1)\n",
    "\n",
    "# Print the size of the data\n",
    "print(\"Dataframe heart_rate has \" + toString(nrow(heart_rate)) + \" rows.\")\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.7\n",
    "\n",
    "# Initialize smoothed_value\n",
    "smoothed_value = heart_rate[1]\n",
    "\n",
    "# Vector to store execution times\n",
    "number_of_executions = 10\n",
    "execution_times = matrix(0, number_of_executions, 1)\n",
    "\n",
    "# Perform exponential smoothing on the data\n",
    "for (i in 1:number_of_executions) {\n",
    "    start_time = time()\n",
    "\n",
    "    # Vectorized exponential smoothing\n",
    "    n = nrow(heart_rate)\n",
    "    weights = rev(alpha * (1 - alpha) ^ seq(0, n-1, 1))\n",
    "    smoothed = rev(cumsum(weights * heart_rate))\n",
    "    smoothed_value = smoothed[1] / sum(weights)\n",
    "\n",
    "    # End timing and calculate execution time\n",
    "    end_time = time()\n",
    "    function_time = (end_time - start_time) / 1000000000 # Convert nanoseconds to seconds\n",
    "    print(function_time)\n",
    "    execution_times[i, 1] = function_time\n",
    "}\n",
    "\n",
    "# Calculate the function time\n",
    "function_time <- avg(execution_times)\n",
    "\n",
    "# Print the results\n",
    "print('### Dataset heart_rate')\n",
    "print('### #1 Basic For Loop \\n')\n",
    "print('The last smoothed value for wind_speed is: ' + toString(smoothed_value))\n",
    "print('The function was executed in ' + toString(function_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/heart_rate/hr_experiment4.dml -exec singlenode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "19.149284084\n",
    "17.080834125\n",
    "16.240216375\n",
    "15.887738625\n",
    "15.558642542\n",
    "15.554881666\n",
    "15.2110245\n",
    "15.661771958\n",
    "15.327253833\n",
    "15.048907625\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 98,778\n",
    "\n",
    "The function was executed in 16.072055533300002 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for heart_rate is: 98,778\n",
    "\n",
    "The function was executed in 16.197294208 seconds\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t55,973 sec.\n",
    "Total compilation time:\t\t0,274 sec.\n",
    "Total execution time:\t\t55,700 sec.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t11/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t1/6/5/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t39,488/0,000/0,618/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/2.\n",
    "HOP DAGs recompile time:\t0,022 sec.\n",
    "Total JIT compile time:\t\t1.882 sec.\n",
    "Total JVM GC count:\t\t41.\n",
    "Total JVM GC time:\t\t0.249 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)  Count\n",
    "  1  nrow          39,492      1\n",
    "  2  ^             11,773      1\n",
    "  3  *              1,262      2\n",
    "  4  ucumk+         1,086      1\n",
    "  5  rev            0,926      2\n",
    "  6  uak+           0,574      1\n",
    "  7  seq            0,547      1\n",
    "  8  -              0,007      3\n",
    "  9  rmvar          0,006     21\n",
    " 10  toString       0,004      1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/heart_rate/hr_experiment3.dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "4522.076746792\n",
    "4569.310003709\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #1 Basic For Loop \n",
    "\n",
    "The last smoothed value for wind_speed is: 98,778\n",
    "\n",
    "The function was executed in 4545.6933752505 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #3 For Loop \n",
    "\n",
    "The last smoothed value for heart_rate is: 98,778\n",
    "\n",
    "The function was executed in 4637.079888875 seconds   # 77 minutes\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t4683,562 sec.\n",
    "Total compilation time:\t\t0,411 sec.\n",
    "Total execution time:\t\t4683,152 sec.\n",
    "Number of compiled Spark inst:\t8.\n",
    "Number of executed Spark inst:\t0.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t415685154/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t0/1/0/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t60,577/7,298/18,413/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t1/103921292.\n",
    "HOP DAGs recompile time:\t4226,406 sec.\n",
    "Spark ctx create time (lazy):\t0,000 sec.\n",
    "Spark trans counts (par,bc,col):0/0/0.\n",
    "Spark trans times (par,bc,col):\t0,000/0,000/0,000 secs.\n",
    "Total JIT compile time:\t\t10.718 sec.\n",
    "Total JVM GC count:\t\t1091.\n",
    "Total JVM GC time:\t\t5.234 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)      Count\n",
    "  1  createvar    104,203  311763868\n",
    "  2  +*            94,436  103921288\n",
    "  3  rightIndex    75,585  103921289\n",
    "  4  *             49,593  103921288\n",
    "  5  sp_csvrblk    45,948          1\n",
    "  6  rmvar         27,169  207842582\n",
    "  7  mvvar         18,915  103921301\n",
    "  8  toString       0,023          1\n",
    "  9  -              0,009          2\n",
    " 10  +              0,004          7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx7g -Xms7g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\" \\\n",
    "     org.apache.sysds.api.DMLScript \\\n",
    "     -f /Users/niklas/Documents/GitHub/Uni/10_Masterarbeit/systemDS_Scripts/heart_rate/hr_experiment4.dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# New Run without -stats\n",
    "\n",
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "20.793400541\n",
    "17.764628916\n",
    "18.353478125\n",
    "16.967458917\n",
    "17.003416208\n",
    "16.24676275\n",
    "16.053267083\n",
    "16.778378583\n",
    "16.063659917\n",
    "16.149777709\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #2 Vectorized \n",
    "\n",
    "The last smoothed value for wind_speed is: 98,778\n",
    "\n",
    "The function was executed in 17.2174228749 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Dataframe heart_rate has 103921289 rows.\n",
    "\n",
    "### Dataset heart_rate\n",
    "### #4 For Loop \n",
    "\n",
    "The last smoothed value for heart_rate is: 98,778\n",
    "\n",
    "The function was executed in 18.972938417 seconds\n",
    "\n",
    "SystemDS Statistics:\n",
    "Total elapsed time:\t\t65,439 sec.\n",
    "Total compilation time:\t\t1,238 sec.\n",
    "Total execution time:\t\t64,201 sec.\n",
    "Number of compiled Spark inst:\t12.\n",
    "Number of executed Spark inst:\t0.\n",
    "Cache hits (Mem/Li/WB/FS/HDFS):\t11/0/0/0/1.\n",
    "Cache writes (Li/WB/FS/HDFS):\t1/7/6/0.\n",
    "Cache times (ACQr/m, RLS, EXP):\t45,198/0,000/3,404/0,000 sec.\n",
    "HOP DAGs recompiled (PRED, SB):\t0/3.\n",
    "HOP DAGs recompile time:\t0,016 sec.\n",
    "Spark ctx create time (lazy):\t0,583 sec.\n",
    "Spark trans counts (par,bc,col):0/0/0.\n",
    "Spark trans times (par,bc,col):\t0,000/0,000/0,000 secs.\n",
    "Total JIT compile time:\t\t3.796 sec.\n",
    "Total JVM GC count:\t\t31.\n",
    "Total JVM GC time:\t\t0.491 sec.\n",
    "Heavy hitter instructions:\n",
    "  #  Instruction  Time(s)  Count\n",
    "  1  sp_csvrblk    45,209      1\n",
    "  2  ^             14,188      1\n",
    "  3  rev            1,311      2\n",
    "  4  *              1,247      2\n",
    "  5  ucumk+         1,089      1\n",
    "  6  uak+           0,652      1\n",
    "  7  seq            0,472      1\n",
    "  8  -              0,008      3\n",
    "  9  toString       0,007      1\n",
    " 10  rmvar          0,004     18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warnings & Errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "WARN utils.SettingsChecker: Low memory budget of total:   8192 GB set to:      8 GB\n",
    "WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ERROR spark.SparkContext: Error initializing SparkContext.\n",
    "org.apache.spark.SparkException: A master URL must be set in your configuration\n",
    "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:414)\n",
    "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext.createContext(SparkExecutionContext.java:277)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext.initSparkContext(SparkExecutionContext.java:248)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext.getSparkContextStatic(SparkExecutionContext.java:163)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext$SparkClusterConfig.analyzeSparkParallelismConfiguation(SparkExecutionContext.java:1975)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext$SparkClusterConfig.analyzeSparkConfiguation(SparkExecutionContext.java:1949)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext$SparkClusterConfig.<init>(SparkExecutionContext.java:1870)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext.getSparkClusterConfig(SparkExecutionContext.java:1780)\n",
    "\tat org.apache.sysds.runtime.controlprogram.context.SparkExecutionContext.getBroadcastMemoryBudget(SparkExecutionContext.java:1790)\n",
    "\tat org.apache.sysds.hops.OptimizerUtils.checkSparkBroadcastMemoryBudget(OptimizerUtils.java:585)\n",
    "\tat org.apache.sysds.hops.UnaryOp.constructCumOffBinary(UnaryOp.java:320)\n",
    "\tat org.apache.sysds.hops.UnaryOp.constructLopsSparkCumulativeUnary(UnaryOp.java:308)\n",
    "\tat org.apache.sysds.hops.UnaryOp.constructLops(UnaryOp.java:168)\n",
    "\tat org.apache.sysds.hops.ReorgOp.constructLops(ReorgOp.java:171)\n",
    "\tat org.apache.sysds.hops.IndexingOp.constructLops(IndexingOp.java:142)\n",
    "\tat org.apache.sysds.hops.BinaryOp.constructLopsBinaryDefault(BinaryOp.java:444)\n",
    "\tat org.apache.sysds.hops.BinaryOp.constructLops(BinaryOp.java:237)\n",
    "\tat org.apache.sysds.hops.DataOp.constructLops(DataOp.java:311)\n",
    "\tat org.apache.sysds.parser.DMLTranslator.constructLops(DMLTranslator.java:435)\n",
    "\tat org.apache.sysds.parser.DMLTranslator.constructLops(DMLTranslator.java:348)\n",
    "\tat org.apache.sysds.api.DMLScript.execute(DMLScript.java:457)\n",
    "\tat org.apache.sysds.api.DMLScript.executeScript(DMLScript.java:319)\n",
    "\tat org.apache.sysds.api.DMLScript.main(DMLScript.java:205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "java -Xmx8g -Xms8g -cp \"./lib/*:/Users/niklas/Documents/GitHub/systemds/target/SystemDS.jar\"      \n",
    "org.apache.sysds.api.DMLScript      \n",
    "-f /Users/niklas/Documents/SystemDS/systemds-3.2.0-bin/experiments/heart_rate/hr_experiment2.dml \n",
    "-exec hadoop -stats\n",
    "24/06/20 10:17:12 ERROR api.DMLScript: \n",
    "Parsing Exception Invalid argument specified for -exec option, must be one of [hadoop, singlenode, hybrid, HYBRID, spark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Gelöst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Exception in thread \"main\" java.lang.NoClassDefFoundError: scala/collection/immutable/List\n",
    "\tat org.apache.sysds.lops.Checkpoint.<clinit>(Checkpoint.java:43)\n",
    "\tat org.apache.sysds.hops.Hop.constructAndSetCheckpointLopIfRequired(Hop.java:494)\n",
    "\tat org.apache.sysds.hops.Hop.constructAndSetLopsDataFlowProperties(Hop.java:427)\n",
    "\tat org.apache.sysds.hops.DataOp.constructLops(DataOp.java:333)\n",
    "\tat org.apache.sysds.hops.DataOp.constructLops(DataOp.java:311)\n",
    "\tat org.apache.sysds.parser.DMLTranslator.constructLops(DMLTranslator.java:435)\n",
    "\tat org.apache.sysds.parser.DMLTranslator.constructLops(DMLTranslator.java:348)\n",
    "\tat org.apache.sysds.api.DMLScript.execute(DMLScript.java:457)\n",
    "\tat org.apache.sysds.api.DMLScript.executeScript(DMLScript.java:319)\n",
    "\tat org.apache.sysds.api.DMLScript.main(DMLScript.java:205)\n",
    "Caused by: java.lang.ClassNotFoundException: scala.collection.immutable.List\n",
    "\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n",
    "\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n",
    "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
    "\t... 10 more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
